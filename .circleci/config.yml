version: 2.1

# Config for CI/CD pipeline

# There is a strong connection between this file and the equivalent files for
# running Dark in dev, which are scripts/builder and
# scripts/build/_build-server. Generally, if you add something to this file,
# there's an equivalent to be added in one of those files.

executors:
  simple-executor:
    docker:
      - image: cimg/base:2021.12
  in-container:
    working_directory: ~/app
    environment:
      IN_DEV_CONTAINER: true
    docker:
      # DOCKERFILE_REPO: see Dockerfile note about how this is built.
      - image: darklang/dark-base:48713d2
  # Rust is so big we create a separate container for it and only use that
  # for rust builds
  in-rust-container:
    working_directory: ~/app
    environment:
      IN_DEV_CONTAINER: true
    docker:
      # DOCKERFILE_REPO: see Dockerfile note about how this is built.
      - image: darklang/dark-rust:48713d2

commands:
  show-large-files-and-directories:
    steps:
      - run:
          # show any file or directory over 50M in size
          # note alpine find doesn't support +50M here
          name: show large files and directories
          command: |
            find ~ -size +51200k -exec du -h {} \;
            du -ht 50M

  ##########################
  # Check the worktree
  ##########################
  assert-clean-worktree:
    steps:
      - run:
          name: Assert the worktree is clean
          command: "bash -c '[[ -z $(git status -s) ]] && echo Workdir is clean || { echo Workdir is not clean:; git status -s; $(exit 1); }'"

  ##########################
  # Checkout - need to remove some things for a clean checkout
  ##########################
  darkcheckout:
    steps:
      # To get ownership right when mounting volumes in local development, the
      # container adds a bunch of directories within ~/app. However, in Circle,
      # we don't use volumes and the container is loaded before the git
      # checkout, which complains if the checkout directory is not empty. So
      # let's delete those first.
      - run: rm -Rf /home/dark/app/*
      - checkout

  ##########################
  # Setup app
  ##########################
  setup-app:
    steps:
      - run:
          name: Setup build environment
          command: |
            set -x
            scripts/devcontainer/_setup-circleci-environment
            scripts/devcontainer/_create-app-directories
            scripts/devcontainer/_create-cache-directories
            scripts/devcontainer/_setup-hosts
            scripts/devcontainer/_start-background-services postgresql
            env

  ##########################
  # Slack
  ##########################
  slack-notify-failure:
    parameters:
      buildType: { type: string } # build or deploy
    steps:
      - run:
          name: Slack notification
          when: on_fail
          command: |
            curl -v -X POST -H 'Content-type: application/json' -d "{ \"success\": false, \"buildType\": \"<<parameters.buildType>>\", \"branch\": \"$CIRCLE_BRANCH\", \"url\": \"$CIRCLE_BUILD_URL\", \"prs\": \"$CIRCLE_PULL_REQUESTS\", \"sha\": \"$CIRCLE_SHA1\", \"username\": \"$CIRCLE_USERNAME\", \"job\": \"$CIRCLE_JOB\" }" https://ops-circleci.builtwithdark.com/notify-slack

  slack-notify-success:
    parameters:
      buildType: { type: string } # build or deploy
    steps:
      - run:
          name: Slack notification
          when: on_success
          command: |
            curl -v -X POST -H 'Content-type: application/json' -d "{ \"success\": true, \"buildType\": \"<<parameters.buildType>>\", \"branch\": \"$CIRCLE_BRANCH\", \"url\": \"$CIRCLE_BUILD_URL\", \"prs\": \"$CIRCLE_PULL_REQUESTS\", \"sha\": \"$CIRCLE_SHA1\", \"username\": \"$CIRCLE_USERNAME\", \"job\": \"$CIRCLE_JOB\" }" https://ops-circleci.builtwithdark.com/notify-slack

  slack-notify-job-failure:
    steps:
      - slack-notify-failure:
          buildType: "job"
  slack-notify-deploy:
    steps:
      - slack-notify-failure:
          buildType: "deploy"
      - slack-notify-success:
          buildType: "deploy"
  slack-notify-build:
    steps:
      - slack-notify-failure:
          buildType: "build"
      - slack-notify-success:
          buildType: "build"




  ##########################
  # Rust
  ##########################
  rust-setup:
    parameters:
      project: { type: string }
      dir: { type: string }
    steps:
      - setup-app
      - restore_cache:
          keys:
            # This cache should be about 500MB or so. It balloons over time and needs to be deleted.
            - v1d-<< parameters.project >>-{{ checksum "<< parameters.dir >>/Cargo.lock" }}-{{ .Branch }}
            - v1d-<< parameters.project >>-{{ checksum "<< parameters.dir >>/Cargo.lock" }}
            - v1d-<< parameters.project >>

  rust-finish:
    parameters:
      project: { type: string }
      dir: { type: string }
    steps:
      - run:
          name: Reduce caches
          command: cargo cache -a
      - show-large-files-and-directories

      # must persist to workspace first, as next step will remove built release artifact
      - persist_to_workspace:
          root: "."
          paths:
            [
              << parameters.dir >>/target/release/dark-<< parameters.project >>,
            ]

      # This removes files in the top-level of target/{debug,release}, which include the actual built artifact
      # and other intermediates that will always be rebuilt on the next build (so there's no sense in caching them).
      # It also includes our own (dark*) build files from deps, which are likewise always rebuilt.
      #
      # See https://github.com/rust-lang/cargo/issues/5885 for discussion and details
      - run:
          name: Cleanup frequently changing rust artifacts
          command: |
            find << parameters.dir >>/target -maxdepth 2 -type f -delete
            rm -rf << parameters.dir >>/target/{debug,release}/{deps,.fingerprint}/dark*

      # https://doc.rust-lang.org/nightly/cargo/guide/cargo-home.html#caching-the-cargo-home-in-ci
      - save_cache:
          name: "Save << parameters.project >> cache"
          paths:
            - << parameters.dir >>/target
            - .cargo/bin/
            - .cargo/registry/index/
            - .cargo/registry/cache/
            - .cargo/git/db/
          key: v1d-<< parameters.project >>-{{ checksum "<< parameters.dir >>/Cargo.lock" }}-{{ .Branch }}

  ##########################
  # Initializing the containers
  ##########################
  prep-container-creation:
    steps:
      - setup_remote_docker: { docker_layer_caching: true, version: 20.10.11 }

      # Save the docker env: type .docker-env when sshing in, then you can
      # use ./scripts/run-in-docker
      - run:
          name: Setup docker-env for debugging
          command: env | grep 'DOCKER\|NO_PROXY' | sed 's/^/export /' > ../docker-env

  build-gcp-containers:
    steps:
      - prep-container-creation
      - run:
          name: Regenerate combined ETags
          command: |
            scripts/build/_generate-etags
            cat backend/static/etags.json
            scripts/linting/_check-etags
            cp backend/static/etags.json rundir/
      - store_artifacts: { path: backend/static/etags.json }
      - run: scripts/build/compile-project shipit
      - run: scripts/deployment/shipit containers build --save-manifest=gcr-image-ids.json
      - run: cat gcr-image-ids.json
      # Test them
      - run: scripts/deployment/shipit release prepare --arg CHANGE_CAUSE="test" --manifest=gcr-image-ids.json

  ##########################
  # misc
  ##########################
  auth-with-gcp:
    parameters: { background: { type: boolean } }
    steps:
      - run:
          name: Auth with GCP
          background: << parameters.background >>
          command: |
            echo $GCLOUD_SERVICE_KEY | base64 --decode --ignore-garbage > gcloud-service-key.json
            gcloud auth activate-service-account --key-file gcloud-service-key.json
            gcloud auth configure-docker
            ./scripts/production/gcp-authorize-kubectl

##########################
# Actual workflow
##########################
jobs:
  build-client:
    executor: in-container
    steps:
      - darkcheckout
      - setup-app
      - restore_cache:
          keys:
            - v3-client-{{ checksum "package-lock.json" }}-{{ .Branch }}
            - v3-client-{{ checksum "package-lock.json" }}
            - v3-client
      - run: scripts/build/compile-project client --test
      - assert-clean-worktree
      - show-large-files-and-directories
      - save_cache:
          name: "Save packagejson-specific cache"
          paths: ["node_modules"]
          key: v3-client-{{ checksum "package-lock.json" }}-{{ .Branch }}
      - persist_to_workspace:
          root: "."
          paths:
            - backend/static/
      - store_artifacts: { path: rundir }
      - store_artifacts: { path: backend/static/etags.json }
      - store_test_results: { path: rundir/test_results }
      - slack-notify-job-failure

  build-backend:
    executor: in-container
    steps:
      - darkcheckout
      - setup-app
      - restore_cache:
          keys:
            - v9-backend-{{ checksum "esy.json" }}
            - v9-backend
      # appsupport is needed for a unit test, but it is not needed as part
      # of the backend otherwise. It is compiled as part of the frontend
      # tests.
      - run: touch backend/static/appsupport.js
      - show-large-files-and-directories
      - run: scripts/build/compile-project --test backend
      - assert-clean-worktree
      # Doesn't need to be run post-build, but takes <1s to run
      - run: scripts/linting/ocaml-find-unused backend/test
      - persist_to_workspace:
          # Do this before reducing size of cache
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - _build/default/backend/bin/server.exe
            - _build/default/backend/bin/emergency_login_script.exe
            - _build/default/backend/bin/garbage_collector_worker.exe
            - _build/default/backend/bin/queue_worker.exe
            - _build/default/backend/bin/cron_checker.exe
            - _build/default/backend/bin/legacy_serialization_server.exe
            - _build/default/backend/bin/legacy_fuzzing_server.exe
            - backend/static/analysis.js
      - run:
          name: Reduce size of esy cache
          command: |
            set -x
            rm -Rf /home/dark/.esy/3/b
            # It seems like everything builds and rebuilds fine without
            # these. Other files are needed: .o, .a, .cma, .cmx.
            shopt -s globstar
            rm -f /home/dark/.esy/3/i/**/*.cmt
            rm -f /home/dark/.esy/3/i/**/*.cmti
            rm -f /home/dark/.esy/3/i/**/*.byte
            # These can be very cheaply rebuilt, and are about 400MB
            rm -f /home/dark/app/_build/default/backend/*/*.exe
      - show-large-files-and-directories
      - save_cache:
          paths:
            - _build
            - node_modules
            - /home/dark/.esy
          key: v9-backend-{{ checksum "esy.json" }}
      - store_artifacts: { path: rundir }
      - store_test_results: { path: rundir/test_results }
      - slack-notify-job-failure

  build-fsharp-backend:
    executor: in-container
    resource_class: xlarge
    steps:
      - darkcheckout
      - setup-app
      - run: shasum fsharp-backend/paket.lock fsharp-backend/global.json > ../checksum
      - restore_cache:
          keys:
            - v6-fsharp-backend-{{ checksum "../checksum" }}
            # Fails often enough that it's better not to have a fallback
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      # so the ocamltestserver will load
      - run: touch backend/static/appsupport.js backend/static/app.js backend/static/analysis.js backend/static/app.css
      # For tests
      - run: cp client/static/favicon-32x32.png backend/static/
      - run: scripts/build/_generate-etags
      - run: scripts/build/compile-project fsharp-backend --test
      - assert-clean-worktree
      - persist_to_workspace:
          # Do this before reducing size of cache
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - fsharp-backend/Build/out/ApiServer/Release/net6.0/linux-x64/publish/
            - fsharp-backend/Build/out/BwdServer/Release/net6.0/linux-x64/publish/
            - fsharp-backend/Build/out/QueueWorker/Release/net6.0/linux-x64/publish/
            - fsharp-backend/Build/out/CronChecker/Release/net6.0/linux-x64/publish/
            - fsharp-backend/Build/out/ExecHost/Release/net6.0/linux-x64/publish/
            - backend/static/BlazorWorker.js
            - backend/static/blazor
      - show-large-files-and-directories
      - save_cache:
          paths: [fsharp-backend/Build]
          key: v6-fsharp-backend-{{ checksum "../checksum" }}
      - store_artifacts: { path: rundir }
      - store_test_results: { path: rundir/test_results }
      - slack-notify-job-failure

  static-checks:
    executor: in-rust-container
    steps:
      - darkcheckout
      - run: scripts/linting/shellchecker
      - run: scripts/linting/yamllinter
      - run: scripts/formatting/format check
      - run: scripts/build/compile-project shipit
      - run: scripts/deployment/shipit validate
      - slack-notify-job-failure

  predeployment-checks:
    executor: in-container
    steps:
      - darkcheckout
      - auth-with-gcp: { background: false }
      - run: scripts/build/compile-project shipit
      - run: scripts/deployment/shipit manual diff > /dev/null 2>&1
      - slack-notify-job-failure

  build-stroller:
    executor: in-rust-container
    steps:
      - darkcheckout
      - rust-setup: { project: "stroller", dir: "containers/stroller" }
      - run: scripts/build/compile-project stroller --test
      - assert-clean-worktree
      - rust-finish: { project: "stroller", dir: "containers/stroller" }
      - slack-notify-job-failure

  build-queue-scheduler:
    executor: in-rust-container
    steps:
      - darkcheckout
      - rust-setup: { project: "queue-scheduler", dir: "containers/queue-scheduler" }
      # tests are run in rust-integration-tests
      - run: scripts/build/compile-project queue-scheduler
      - assert-clean-worktree
      - rust-finish: { project: "queue-scheduler", dir: "containers/queue-scheduler" }
      - slack-notify-job-failure

  build-postgres-honeytail:
    executor: simple-executor
    steps:
      - darkcheckout
      - prep-container-creation
      - run: cd containers/postgres-honeytail && docker build -t postgres-honeytail .
      - slack-notify-job-failure

  validate-honeycomb-config:
    executor: simple-executor
    steps:
      - darkcheckout
      - prep-container-creation
      - run: bash -c scripts/linting/test-honeycomb-config.sh
      - slack-notify-job-failure

  integration-tests:
    executor: in-container
    parallelism: 4
    resource_class: large
    steps:
      - darkcheckout
      - setup-app
      - attach_workspace: { at: "." }
      - restore_cache: # get playwright
          keys:
            - v2-playwright-{{ checksum "package-lock.json" }}-{{ .Branch }}
            - v2-playwright-{{ checksum "package-lock.json" }}
            - v2-playwright
      - show-large-files-and-directories
      - run: "cd integration-tests && npm install"
      - run: scripts/build/_generate-etags
      - run:
          name: Prep test split
          command: |
            # get full list of tests
            integration-tests/test-list.sh > rundir/all-tests

            # split them using timing info
            TESTS=$(circleci tests split --split-by=timings --timings-type=testname rundir/all-tests)

            # concat them into a pattern (note: $TESTS is deliberately unquoted)
            PATTERN=$(printf -- "%s|" $TESTS)

            # remove last char
            PATTERN=${PATTERN%?}

            echo $PATTERN > test-pattern
      - run:
          name: Run integration tests
          command: |
            # Run the server first to set up the DB correctly for the prep script
            scripts/run-fsharp-server --published
            # Wait for users to be added so prep.sh works
            ./scripts/devcontainer/_wait-until-apiserver-ready
            integration-tests/run.sh --concurrency=3 --retry --pattern="`cat test-pattern`" --published
            rm test-pattern

      - run: integration-tests/_integration-test-results-to-honeycomb.sh
      - assert-clean-worktree
      - store_artifacts: { path: rundir }
      - store_test_results: { path: rundir/test_results }
      - save_cache:
          name: "Save packagejson-specific cache"
          paths: ["integration-tests/node_modules", "/home/dark/.cache/ms-playwright"]
          key: v2-playwright-{{ checksum "integration-tests/package-lock.json" }}-{{ .Branch }}
      - slack-notify-job-failure


  rust-integration-tests:
    executor: in-rust-container
    steps:
      - darkcheckout
      - rust-setup: { dir: "containers/queue-scheduler", project: "containers/queue-scheduler" }
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - run:
          name: Run DB migrations
          command: |
            # Run the server long enough to ensure it runs the migrations
            ./scripts/run-pubsub-emulator
            cd fsharp-backend
            ./Build/out/ExecHost/Release/net6.0/linux-x64/publish/ExecHost migrations run
      - run:
          name: Run queue-scheduler tests
          command: scripts/run-rust-tests containers/queue-scheduler
      - assert-clean-worktree
      - store_artifacts: { path: rundir }
      - slack-notify-job-failure

  gcp-containers-test:
    executor: in-container
    steps:
      # Just test that we can build them for now
      - darkcheckout
      - setup-app
      - attach_workspace: { at: "." }
      - build-gcp-containers
      - slack-notify-job-failure

  push-to-gcp:
    executor: in-container
    steps:
      - darkcheckout
      - setup-app
      - run: scripts/build/compile-project shipit
      - auth-with-gcp: { background: true }
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - build-gcp-containers
      - persist_to_workspace:
          root: "."
          paths: ["gcr-image-ids.json"]
      - run: scripts/deployment/_push-assets-to-cdn
      - run: scripts/deployment/shipit containers push
      - slack-notify-job-failure

  deploy:
    executor: in-container
    steps:
      - darkcheckout
      - setup-app
      - run: scripts/build/compile-project shipit
      - auth-with-gcp: { background: false }
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - run: scripts/deployment/gke-deploy --manifest=gcr-image-ids.json
      - slack-notify-deploy

  notify-non-deploy:
    executor: simple-executor
    steps:
      - slack-notify-build

workflows:
  version: 2
  build-and-deploy:
    jobs:
      # initial builds & tests
      - static-checks
      - predeployment-checks:
          filters:
            branches:
              ignore: /^(pull\/).*$/
      - build-postgres-honeytail
      - validate-honeycomb-config
      - build-backend
      - build-client
      - build-stroller
      - build-queue-scheduler
      - build-fsharp-backend:
          requires:
            - build-backend

      # expensive tests
      - rust-integration-tests:
          requires:
            - build-backend
            - build-fsharp-backend
            - build-client
            - build-queue-scheduler
      - integration-tests:
          requires:
            - build-backend
            - build-client
            - build-fsharp-backend
      - gcp-containers-test:
          requires:
            - build-client # to rebuild etags
            - build-backend
            - build-fsharp-backend
            - build-stroller
            - build-queue-scheduler

      # pre-deploy, in parallel with integration-tests
      - push-to-gcp:
          filters:
            branches:
              only: main
          requires:
            - build-backend
            - build-fsharp-backend
            - build-client
            - build-stroller
            - build-queue-scheduler
            - build-postgres-honeytail

      # actual deploy
      - deploy:
          filters:
            branches:
              only: main
          requires:
            - validate-honeycomb-config
            - integration-tests
            - rust-integration-tests
            - push-to-gcp
            - static-checks
            - predeployment-checks

      - notify-non-deploy:
          filters:
            branches:
              ignore: main
          requires:
            - build-backend
            - build-client
            - build-fsharp-backend
            - build-postgres-honeytail
            - build-queue-scheduler
            - build-stroller
            - gcp-containers-test
            - integration-tests
            - rust-integration-tests
            - static-checks
            - predeployment-checks
            - validate-honeycomb-config
