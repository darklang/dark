version: 2.1
executors:
  my-executor:
    docker:
      - image: docker:stable-git

commands:
  show-large-files-and-directories:
    steps:
      - run:
          # show any file or directory over 50M in size
          # note alpine find doesn't support +50M here
          name: show large files and directories
          command: |
            find . -size +51200k -exec du -h {} \;
            du -ht 50M

  ##########################
  # Getting into the remote container
  ##########################
  copy-into-container:
    steps:
      - show-large-files-and-directories
      # https://circleci.com/docs/2.0/building-docker-images/#mounting-folders
      - run:
          name: Copy app directory into dev container
          command: |
            time docker cp . vols:/home/dark/app
      - set-ownership:
          path: "/home/dark/app"

  set-ownership:
    parameters:
      path:
        type: string
    steps:
      # https://circleci.com/docs/2.0/building-docker-images/#mounting-folders
      - run:
          name: Set the ownership of copied files
          command: |
            docker run -i --volumes-from vols alpine sh -c "adduser -D -u 1000 dark; chown -R dark << parameters.path >>"

  ##########################
  # Check the worktree
  ##########################
  assert-clean-worktree:
    steps:
      - run:
          name: Assert the worktree is clean
          command: "bash -c '[[ -z $(git status -s) ]] && echo Workdir is clean || { echo Workdir is not clean:; git status -s; $(exit 1); }'"

  ##########################
  # Artifacts
  ##########################
  extract-and-save-artifacts:
    steps:
      - run:
          name: Copy out artifacts
          when: always
          command: |
            set -x
            mkdir -p artifacts
            time docker cp vols:/home/dark/app/rundir artifacts/rundir
            time docker cp vols:/home/dark/app/backend/static/etags.json artifacts/
            ls -la backend/static > artifacts/asset-list.txt
      - store_artifacts:
          path: artifacts
      - store_test_results:
          path: artifacts/rundir/test_results

  ##########################
  # Rust
  ##########################
  rust-setup:
    parameters:
      project:
        type: string
    steps:
      - restore_cache:
          keys:
            # This cache should be about 500MB or so. It balloons over time and needs to be deleted.
            - v14-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}-{{ .Branch }}
            - v14-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}
            - v14-<< parameters.project >>
      - run:
          name: Set up volume for cargo
          command: |
            set -x
            time mkdir -p dotcargo
            time docker cp dotcargo/. vols:/home/dark/.cargo
            time rm -Rf dotcargo # don't copy it a second time when we copy-into-container
      - set-ownership: { path: "/home/dark/.cargo" }

  rust-finish:
    parameters:
      project:
        type: string
    steps:
      - run:
          name: Copy out generated files and caches
          command: |
            set -x
            # clean ~./cargo sources before copy
            scripts/run-in-docker 'cargo cache -a'
            time docker cp vols:/home/dark/app/<< parameters.project >>/target << parameters.project >>/
            time docker cp vols:/home/dark/.cargo dotcargo

      - show-large-files-and-directories

      # must persist to workspace first, as next step will remove built release artifact
      - persist_to_workspace:
          root: "."
          paths: [ << parameters.project >>/target/release/dark-<< parameters.project >> ]

      # This removes files in the top-level of target/{debug,release}, which include the actual built artifact
      # and other intermediates that will always be rebuilt on the next build (so there's no sense in caching them).
      # It also includes our own (dark*) build files from deps, which are likewise always rebuilt.
      #
      # See https://github.com/rust-lang/cargo/issues/5885 for discussion and details
      - run:
          name: Cleanup frequently changing rust artifacts
          command: |
            find << parameters.project >>/target -maxdepth 2 -type f -delete
            rm -rf << parameters.project >>/target/{debug,release}/{deps,.fingerprint}/dark*

      # https://doc.rust-lang.org/nightly/cargo/guide/cargo-home.html#caching-the-cargo-home-in-ci
      - save_cache:
          name: "Save << parameters.project >> cache"
          paths:
            - << parameters.project >>/target
            - dotcargo/bin/
            - dotcargo/registry/index/
            - dotcargo/registry/cache/
            - dotcargo/git/db/
          key: v14-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}-{{ .Branch }}-{{ .BuildNum }}

  ##########################
  # Caches
  ##########################
  clean-caches:
    parameters:
      path:
        type: string
    steps:
      - run:
          name: maybe clear caches
          # since we don't checksum the cache on its contents, it may
          # continue to grow. as a result, let's clear the cache weekly.
          # we store the day the cache was built in the cache. if the
          # cache was built on friday, and today is not friday, then
          # it's the first build after last week, and clear it.
          command: |
            if [[ `date +"%a"` != "friday" && `cat << parameters.path >>/cache_day` == "friday" ]]; then
              echo "clearing caches"
              rm -rf << parameters.path >>
            else
              echo "not clearing caches"
            fi
            mkdir -p << parameters.path >>
            date +"%a" > << parameters.path >>/cache_day

  ##########################
  # Initializing the containers
  ##########################

  setup-cache-names:
    steps:
      - run:
          name: "Setup cache names"
          command: |
            date +"%F" > rundir/today-timestamp
            date +"%F" -d "today - 1 days" > rundir/minus1-timestamp
            date +"%F" -d "today - 2 days" > rundir/minus2-timestamp
            date +"%F" -d "today - 3 days" > rundir/minus3-timestamp

  initialize:
    steps:
      - setup_remote_docker:
          docker_layer_caching: true

      # Save the docker env: type .docker-env when sshing in, then you can
      # use ./scripts/run-in-docker
      - run: |
          env \
          | grep 'DOCKER\|NO_PROXY' \
          | sed 's/^/export /' \
          > /root/docker-env

      - run:
          name: Prepare dev-container volume (vols)
          command: |
            # We list all the directories because volume creation has to be
            # done on creation afaict.
            docker create -v /home/dark/app -v /home/dark/.esy -v /home/dark/.cargo -v /usr/local/cargo-home --name vols alpine:3.4 /bin/true

      - run:
          name: Install outer container utilities
          # coreutils for gnu date
          command: |
            apk add --update bash coreutils jq
      - setup-cache-names


  ##########################
  # misc
  ##########################
  run-background-container:
    steps:
      - run:
          name: Build container if necessary
          command: scripts/builder
      - run:
          name: Run background container
          command: scripts/builder --ci-serve
          background: true
  wait-for-container:
    steps:
      - run:
          name: "Wait for container"
          command: |
            # --foreground because this is run in a script by circle
            timeout --foreground 10m scripts/wait-until-container-ready
  wait-for-server:
    steps:
      - wait-for-container
      - run:
          name: "Wait for server"
          command: |
            # --foreground because this is run in a script by circle
            timeout --foreground 10m scripts/wait-until-server-ready
  auth-with-gcp:
    steps:
      - run:
          name: Auth with GCP
          command: |
            echo $GCLOUD_SERVICE_KEY | base64 --decode --ignore-garbage > gcloud-service-key.json
            docker cp gcloud-service-key.json dark-dev:/home/dark/app/gcloud-service-key.json
            scripts/run-in-docker gcloud auth activate-service-account --key-file /home/dark/app/gcloud-service-key.json

##########################
# Actual workflow
##########################
jobs:

  build-container:
    executor: my-executor
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
      # Save the docker env: type .docker-env when sshing in, then you can
      # use ./scripts/run-in-docker
      - run: |
          env \
          | grep 'DOCKER\|NO_PROXY' \
          | sed 's/^/export /' \
          > /root/docker-env
      - run: apk add python3 --update-cache 
      - run: pip3 install awscli --upgrade --user
      - run: docker build -t dark-ci .
      - run: docker tag dark-ci:latest 500377317163.dkr.ecr.us-east-1.amazonaws.com/dark-ci:latest
      - run: $(/root/.local/bin/aws ecr get-login --no-include-email --region us-east-1)
      - run: docker push 500377317163.dkr.ecr.us-east-1.amazonaws.com/dark-ci:latest

  build-stroller:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - rust-setup: { project: "stroller" }
      - copy-into-container
      - run: scripts/builder --compile-stroller --test
      - run-background-container
      - wait-for-container
      - run: scripts/gcp-build-containers --skip-ocaml --skip-queue-scheduler
      - assert-clean-worktree
      - rust-finish: { project: "stroller" }

  build-queue-scheduler:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - rust-setup: { project: "queue-scheduler" }
      - copy-into-container
      - run: scripts/builder --compile-scheduler # tests are run in integration-tests job
      - run-background-container
      - wait-for-container
      - run: scripts/gcp-build-containers --skip-ocaml --skip-stroller
      - assert-clean-worktree
      - rust-finish: { project: "queue-scheduler" }

  build-backend:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v12-backend-{{ checksum "rundir/today-timestamp" }}
            - v12-backend-{{ checksum "rundir/minus1-timestamp" }}
            - v12-backend-{{ checksum "rundir/minus2-timestamp" }}
            - v12-backend-{{ checksum "rundir/minus3-timestamp" }}
      - clean-caches: { path: "backend/_build" }
      # appsupport is needed for a unit test
      - run: touch backend/static/appsupport.js
      - show-large-files-and-directories
      - run:
          # Everything else is copied in via copy-into-container, but it
          # doesn't include this because it's not in /home/dark/app.
          name: Set up volume for dotesy
          command: |
            set -x
            mkdir -p dotesy
            time docker cp dotesy/. vols:/home/dark/.esy
            time rm -Rf dotesy # don't copy it a second time
      - set-ownership:
          path: "/home/dark/.esy"
      - copy-into-container
      - run: scripts/builder --compile-backend --test
      - run-background-container
      - wait-for-container
        # For speed optimization, we could put this in a faster job; it doesn't
        # need to be run post-build, it just needs the container running. But it
        # takes <1s to run, so this is the more "logical" location.
      - run: scripts/ocaml-find-unused backend/test
      - assert-clean-worktree
      - run:
          name: Reduce size of esy cache
          command: |
            set -x
            ./scripts/run-in-docker rm -Rf /home/dark/.esy/3/b
      - run:
          name: Copy out generated files and caches
          command: |
            set -x
            time docker cp vols:/home/dark/app/backend/_build backend/
            time docker cp vols:/home/dark/app/backend/_esy backend/
            time docker cp vols:/home/dark/app/backend/node_modules backend/
            time docker cp vols:/home/dark/app/backend/static/. backend/static
            time docker cp vols:/home/dark/.esy dotesy
      - show-large-files-and-directories
      - save_cache:
          name: "Save daily backend cache"
          paths:
            - backend/_build
            - backend/_esy
            - backend/node_modules
            - backend/static
            - dotesy
          key: v12-backend-{{ checksum "rundir/today-timestamp" }}
      - persist_to_workspace:
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - backend/_build/default/bin/server.exe
            - backend/_build/default/bin/queue_worker.exe
            - backend/_build/default/bin/cron_checker.exe
            - backend/static/analysis.js
      - run:
          name: Copy out artifacts
          when: always
          command: |
            set -x
            mkdir -p artifacts
            time docker cp vols:/home/dark/app/rundir artifacts/rundir
      - store_artifacts:
          path: artifacts
      - store_test_results:
          path: artifacts/rundir/test_results

  build-postgres-honeytail:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v6-postgres-honeytail-{{ checksum "rundir/today-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "rundir/minus1-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "rundir/minus2-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "rundir/minus3-timestamp" }}
      - run: cd postgres-honeytail && docker build -t dark-gcp-postgres-honeytail .

  validate-honeycomb-config:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - run: apk add --update python py-pip && pip install yq
      - run: pip install yq
      - run: scripts/support/test-honeycomb-config.sh

  build-client:
    docker:
      - image: 500377317163.dkr.ecr.us-east-1.amazonaws.com/dark-ci:latest
    steps:
      - checkout
      - restore_cache:
          keys:
            - v0d-client-{{ checksum "client/package.json" }}
            - v0d-client-{{ checksum "client/yarn.lock" }}-{{ .Branch }}
            - v0d-client-{{ checksum "client/yarn.lock" }}
            - v0d-client
      - run: scripts/support/build-server --compile-client --test
      - assert-clean-worktree
      - run: scripts/support/shellchecker # run here cause its the fastest
      - show-large-files-and-directories
      - save_cache:
          name: "Save packagejson-specific cache"
          paths: [ "client/node_modules" ]
          key: v0d-client-{{ checksum "client/package.json" }}
      - persist_to_workspace:
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - backend/static/app.css
            - backend/static/app.js
            - backend/static/appsupport.js
            - backend/static/fetcher.js
            - backend/static/analysiswrapper.js
      - run:
          name: Prepare artifacts
          when: always
          command: |
            cp backend/static/etags.json rundir
            ls -la backend/static > rundir/asset-list.txt
      - store_artifacts:
          path: /home/dark/app/rundir
      - store_test_results:
          path: artifacts/rundir/test_results



  integration-tests:
    executor: my-executor
    parallelism: 4
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - restore_cache: # get testcafe
          keys:
            - v9-client-{{ checksum "client/package.json" }}
            - v9-client-{{ checksum "rundir/today-timestamp" }}
            - v9-client-{{ checksum "rundir/minus1-timestamp" }}
            - v9-client-{{ checksum "rundir/minus2-timestamp" }}
            - v9-client-{{ checksum "rundir/minus3-timestamp" }}
      - show-large-files-and-directories
      - copy-into-container
      - run-background-container

      - wait-for-server
      - run:
          name: Run integration tests
          shell: bash
          command: |
            # get full list of tests
            grep ^test integration-tests/tests.js | sed 's/.*"\(.*\)".*/\1/' > rundir/all-tests
            # split them using timing info
            TESTS=$(circleci tests split --split-by=timings --timings-type=testname rundir/all-tests)
            # concat them into a pattern (note: $TESTS is deliberately unquoted)
            PATTERN=$(printf -- "^%s$|" $TESTS)
            # remove last char
            PATTERN=${PATTERN%?}
            scripts/run-in-docker integration-tests/run.sh --pattern="$PATTERN"
      - assert-clean-worktree

      - extract-and-save-artifacts

  rust-integration-tests:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - rust-setup: { project: "queue-scheduler" }
      - copy-into-container
      - run-background-container
      - wait-for-server
      - run:
          name: Run queue-scheduler tests
          command: scripts/run-in-docker scripts/run-rust-tests queue-scheduler
      - assert-clean-worktree


  push-to-gcp:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - copy-into-container
      - run-background-container
      # Now that the workspaces have combined, we need to regenerate etags.json
      - wait-for-server
      - run: docker cp vols:/home/dark/app/backend/static/etags.json backend/static
      - run: scripts/run-in-docker scripts/gcp-build-containers
      - auth-with-gcp
      - run: scripts/run-in-docker scripts/push-assets-to-cdn
      - run: scripts/run-in-docker scripts/gcp-push-images-to-gcr
      # Save the image IDs for deployment later
      - run: |
          set -x
          mkdir gcr-image-ids
          time docker images gcr.io/balmy-ground-195100/dark-gcp -q | head -n 1 > gcr-image-ids/server
          time docker images gcr.io/balmy-ground-195100/dark-gcp-qw -q | head -n 1 > gcr-image-ids/qw
          time docker images gcr.io/balmy-ground-195100/dark-gcp-cron -q | head -n 1 > gcr-image-ids/cron
          time docker images gcr.io/balmy-ground-195100/dark-gcp-stroller -q | head -n 1 > gcr-image-ids/stroller
          time docker images gcr.io/balmy-ground-195100/dark-gcp-queue-scheduler -q | head -n 1 > gcr-image-ids/queue-scheduler
          time docker images gcr.io/balmy-ground-195100/tunnel -q | head -n 1 > gcr-image-ids/tunnel
          time docker images gcr.io/balmy-ground-195100/dark-gcp-postgres-honeytail -q | head -n 1 > gcr-image-ids/postgres-honeytail
      - persist_to_workspace:
          root: "."
          paths: [ gcr-image-ids ]


  deploy:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - copy-into-container
      - run-background-container
      - wait-for-container
      - auth-with-gcp
      - run: |
          scripts/run-in-docker scripts/gke-deploy       \
            --server-image-id=`cat gcr-image-ids/server` \
            --qw-image-id=`    cat gcr-image-ids/qw`     \
            --cron-image-id=`  cat gcr-image-ids/cron`   \
            --stroller-image-id=`cat gcr-image-ids/stroller` \
            --queue-scheduler-image-id=`cat gcr-image-ids/queue-scheduler` \
            --tunnel-image-id=`cat gcr-image-ids/tunnel` \
            --postgres-honeytail-image-id=`cat gcr-image-ids/postgres-honeytail`


workflows:
  version: 2
  build-and-deploy:
    jobs:
      # initial builds & tests
      - build-container
      - build-postgres-honeytail
      - validate-honeycomb-config

      - build-backend: { requires: [ build-container ] }
      - build-client: { requires: [ build-container ] }
      - build-stroller: { requires: [ build-container ] }
      - build-queue-scheduler: { requires: [ build-container ] }

      # expensive tests
      - rust-integration-tests:
          requires:
            - build-backend
            - build-client
            - build-queue-scheduler
      - integration-tests:
          requires:
            - build-backend
            - build-client

      # pre-deploy, in parallel with integration-tests
      - push-to-gcp:
          filters:
            branches:
              only: master
          requires:
            - build-backend
            - build-client
            - build-stroller
            - build-queue-scheduler
            - build-postgres-honeytail

      # actual deploy
      - deploy:
          filters:
            branches:
              only: master
          requires:
            - validate-honeycomb-config
            - integration-tests
            - rust-integration-tests
            - push-to-gcp
