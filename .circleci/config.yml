version: 2.1
executors:
  my-executor:
    docker:
      - image: docker:stable-git

commands:
  ##########################
  # Getting into the remote container
  ##########################
  copy-into-container:
    steps:
      - run:
          command: |
            set +ex
            du -hs .
            du -hs *
            du --human-readable --count --threshold=5M
      # https://circleci.com/docs/2.0/building-docker-images/#mounting-folders
      - run:
          name: Copy app directory into dev container
          command: |
            docker cp . vols:/home/dark/app
      - set-ownership:
          path: "/home/dark/app"

  set-ownership:
    parameters:
      path:
        type: string
    steps:
      # https://circleci.com/docs/2.0/building-docker-images/#mounting-folders
      - run:
          name: Set the ownership of copied files
          command: |
            docker run -i --volumes-from vols alpine sh -c "adduser -D -u 1000 dark; chown -R dark << parameters.path >>"

  ##########################
  # Check the worktree
  ##########################
  assert-clean-worktree:
    steps:
      - run:
          name: Assert the worktree is clean
          command: "bash -c '[[ -z $(git status -s) ]] && echo Workdir is clean || { echo Workdir is not clean:; git status -s; $(exit 1); }'"

  ##########################
  # Artifacts
  ##########################
  extract-and-save-artifacts:
    steps:
      - run:
          name: Copy out artifacts
          when: always
          command: |
            mkdir -p artifacts
            docker cp vols:/home/dark/app/rundir artifacts/rundir
            docker cp vols:/home/dark/app/backend/static/etags.json artifacts/
            ls -la backend/static > artifacts/asset-list.txt
      - store_artifacts:
          path: artifacts
      - store_test_results:
          path: artifacts/rundir/test_results

  rust-setup:
    parameters:
      project:
        type: string
    steps:
      - restore_cache:
          keys:
            - v12-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}-{{ .Branch }}
            - v12-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}
            - v12-<< parameters.project >>
      - run:
          command: |
            set +ex
            du -hs *
            du -hs dotcargo/*
            du --human-readable --count --threshold=5M
      - run:
          name: Set up volume for cargo
          command: |
            mkdir -p dotcargo
            docker cp dotcargo/. vols:/home/dark/.cargo
            rm -Rf dotcargo # don't copy it a second time when we copy-into-container
      - set-ownership: { path: "/home/dark/.cargo" }

  rust-cache:
    parameters:
      project:
        type: string
    steps:
      - run:
          name: Copy out generated files and caches
          command: |
            docker cp vols:/home/dark/app/<< parameters.project >>/target << parameters.project >>/
            docker cp vols:/home/dark/.cargo dotcargo
      - run:
          command: |
            set +ex
            du -hs *
            du -hs << parameters.project >>/target
            du -hs dotcargo/*
            du --human-readable --count --threshold=5M
      # https://doc.rust-lang.org/nightly/cargo/guide/cargo-home.html#caching-the-cargo-home-in-ci
      - save_cache:
          name: "Save << parameters.project >> cache"
          paths:
            - << parameters.project >>/target
            - dotcargo/bin/
            - dotcargo/registry/index/
            - dotcargo/registry/cache/
            - dotcargo/git/db/
          key: v12-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}-{{ .Branch }}-{{ .BuildNum }}
      - persist_to_workspace:
          root: "."
          paths:
            - << parameters.project>>/target


  ##########################
  # Caches
  ##########################
  clean-caches:
    parameters:
      path:
        type: string
    steps:
      - run:
          name: maybe clear caches
          # since we don't checksum the cache on its contents, it may
          # continue to grow. as a result, let's clear the cache weekly.
          # we store the day the cache was built in the cache. if the
          # cache was built on friday, and today is not friday, then
          # it's the first build after last week, and clear it.
          command: |
            if [[ `date +"%a"` != "friday" && `cat << parameters.path >>/cache_day` == "friday" ]]; then
              echo "clearing caches"
              rm -rf << parameters.path >>
            else
              echo "not clearing caches"
            fi
            mkdir -p << parameters.path >>
            date +"%a" > << parameters.path >>/cache_day

  ##########################
  # Initializing the containers
  ##########################
  initialize:
    steps:
      - setup_remote_docker:
          docker_layer_caching: true

      # Save the docker env: type .docker-env when sshing in, then you can
      # use ./scripts/run-in-docker
      - run: |
          env \
          | grep 'DOCKER\|NO_PROXY' \
          | sed 's/^/export /' \
          > /root/docker-env

      - run:
          name: Prepare dev-container volume (vols)
          command: |
            # We list all the directories because volume creation has to be
            # done on creation afaict.
            docker create -v /home/dark/app -v /home/dark/.esy -v /home/dark/.cargo -v /usr/local/cargo-home --name vols alpine:3.4 /bin/true

      - run:
          name: Install outer container utilities
          # coreutils for gnu date
          command: |
            apk add --update bash coreutils jq

      - run:
          name: "Setup cache names"
          command: |
            date +"%F" > rundir/today-timestamp
            date +"%F" -d "today - 1 days" > rundir/minus1-timestamp
            date +"%F" -d "today - 2 days" > rundir/minus2-timestamp
            date +"%F" -d "today - 3 days" > rundir/minus3-timestamp


  ##########################
  # misc
  ##########################
  run-background-container:
    steps:
      - run:
          name: Build container if necessary
          command: scripts/builder
      - run:
          name: Run background container
          command: scripts/builder --ci-serve
          background: true
  wait-for-container:
    steps:
      - run:
          name: "Wait for container"
          command: |
            # --foreground because this is run in a script by circle
            timeout --foreground 10m scripts/wait-until-container-ready
  wait-for-server:
    steps:
      - wait-for-container
      - run:
          name: "Wait for server"
          command: |
            # --foreground because this is run in a script by circle
            timeout --foreground 10m scripts/wait-until-server-ready
  auth-with-gcp:
    steps:
      - run:
          name: Auth with GCP
          command: |
            echo $GCLOUD_SERVICE_KEY | base64 --decode --ignore-garbage > gcloud-service-key.json
            docker cp gcloud-service-key.json dark-dev:/home/dark/app/gcloud-service-key.json
            scripts/run-in-docker gcloud auth activate-service-account --key-file /home/dark/app/gcloud-service-key.json

##########################
# Actual workflow
##########################
jobs:
  build-stroller:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - rust-setup: { project: "stroller" }
      - copy-into-container
      - run: scripts/builder --compile-stroller --test
      - run-background-container
      - wait-for-container
      - run: scripts/gcp-build-containers --skip-ocaml --skip-queue-scheduler
      - assert-clean-worktree
      - rust-cache: { project: "stroller" }

  build-queue-scheduler:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - rust-setup: { project: "queue-scheduler" }
      - copy-into-container
      - run: scripts/builder --compile-scheduler # tests are run in integration-tests job
      - run-background-container
      - wait-for-container
      - run: scripts/gcp-build-containers --skip-ocaml --skip-stroller
      - assert-clean-worktree
      - rust-cache: { project: "queue-scheduler" }

  build-backend:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v11-backend-{{ checksum "rundir/today-timestamp" }}
            - v11-backend-{{ checksum "rundir/minus1-timestamp" }}
            - v11-backend-{{ checksum "rundir/minus2-timestamp" }}
            - v11-backend-{{ checksum "rundir/minus3-timestamp" }}
      - clean-caches: { path: "backend/_build" }
      - clean-caches: { path: "dotesy" }
      # appsupport is needed for a unit test
      - run: touch backend/static/appsupport.js
      - run:
          command: |
            set +ex
            du -hs *
            du -hs backend/*
            du --human-readable --count --threshold=5M
      - run:
          # Everything else is copied in via copy-into-container, but it
          # doesn't include this because it's not in /home/dark/app.
          name: Set up volume for dotesy
          command: |
            mkdir -p dotesy
            docker cp dotesy/. vols:/home/dark/.esy
            rm -Rf dotesy # don't copy it a second time
      - set-ownership:
          path: "/home/dark/.esy"
      - copy-into-container
      - run: scripts/builder --compile-backend --test
      - run-background-container
      - wait-for-container
        # For speed optimization, we could put this in a faster job; it doesn't
        # need to be run post-build, it just needs the container running. But it
        # takes <1s to run, so this is the more "logical" location.
      - run: scripts/ocaml-find-unused backend/test
      - assert-clean-worktree
      - run:
          name: Reduce size of esy cache
          command: |
            ./scripts/run-in-docker rm -Rf /home/dark/.esy/3/b
      - run:
          name: Copy out generated files and caches
          command: |
            docker cp vols:/home/dark/app/backend/_build backend/
            docker cp vols:/home/dark/app/backend/_esy backend/
            docker cp vols:/home/dark/app/backend/node_modules backend/
            docker cp vols:/home/dark/app/backend/static/. backend/static
            docker cp vols:/home/dark/.esy dotesy
      - run:
          command: |
            set +ex
            du -hs *
            du -hs backend/*
            du --human-readable --count --threshold=5M
      - save_cache:
          name: "Save daily backend cache"
          paths:
            - backend/_build
            - backend/_esy
            - backend/node_modules
            - backend/static
            - dotesy
          key: v11-backend-{{ checksum "rundir/today-timestamp" }}
      - persist_to_workspace:
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - backend/_build
            - backend/static/analysis.js
      - run:
          name: Copy out artifacts
          when: always
          command: |
            mkdir -p artifacts
            docker cp vols:/home/dark/app/rundir artifacts/rundir
      - store_artifacts:
          path: artifacts
      - store_test_results:
          path: artifacts/rundir/test_results

  build-postgres-honeytail:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v6-postgres-honeytail-{{ checksum "rundir/today-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "rundir/minus1-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "rundir/minus2-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "rundir/minus3-timestamp" }}
      - run: cd postgres-honeytail && docker build -t dark-gcp-postgres-honeytail .

  validate-honeycomb-config:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - run: apk add --update python py-pip && pip install yq
      - run: pip install yq
      - run: scripts/support/test-honeycomb-config.sh

  build-client:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v9-client-{{ checksum "client/package.json" }}
            - v9-client-{{ checksum "rundir/today-timestamp" }}
            - v9-client-{{ checksum "rundir/minus1-timestamp" }}
            - v9-client-{{ checksum "rundir/minus2-timestamp" }}
            - v9-client-{{ checksum "rundir/minus3-timestamp" }}
      - clean-caches: { path: "client/node_modules" }
      - clean-caches: { path: "client/lib" }
      - copy-into-container
      - run: scripts/builder --compile-client --test
      - run-background-container
      - wait-for-container
      - assert-clean-worktree
      - run: scripts/support/shellchecker # run here cause its the fastest
      - run:
          name: Copy out generated files and caches
          command: |
            docker cp vols:/home/dark/app/client/node_modules client
            docker cp vols:/home/dark/app/client/lib client
            docker cp vols:/home/dark/app/backend/static/. backend/static
      - run:
          command: |
            set +ex
            du -hs .
            du -hs client/node_modules
            du -hs client/lib
            du -hs backend/static
            du --human-readable --count --threshold=5M
      - save_cache:
          name: "Save packagejson-specific cache"
          paths: [ "client/node_modules" ]
          key: v9-client-{{ checksum "client/package.json" }}
      - save_cache:
          name: "Save daily client cache"
          paths: [ "client/node_modules" ]
          key: v9-client-{{ checksum "rundir/today-timestamp" }}
      - persist_to_workspace:
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - backend/static/app.css
            - backend/static/app.js
            - backend/static/appsupport.js
            - backend/static/fetcher.js
            - backend/static/analysiswrapper.js
      - run:
          name: Copy out artifacts
          when: always
          command: |
            mkdir -p artifacts
            docker cp vols:/home/dark/app/rundir artifacts/rundir
            cp backend/static/etags.json artifacts
            ls -la backend/static > artifacts/asset-list.txt
      - store_artifacts:
          path: artifacts
      - store_test_results:
          path: artifacts/rundir/test_results



  integration-tests:
    executor: my-executor
    parallelism: 4
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - restore_cache: # get testcafe
          keys:
            - v9-client-{{ checksum "client/package.json" }}
            - v9-client-{{ checksum "rundir/today-timestamp" }}
            - v9-client-{{ checksum "rundir/minus1-timestamp" }}
            - v9-client-{{ checksum "rundir/minus2-timestamp" }}
            - v9-client-{{ checksum "rundir/minus3-timestamp" }}

      - run:
          command: |
            set +ex
            du -hs *
            du -hs backend/*
            du -hs client/*
            du --human-readable --count --threshold=5M

      - copy-into-container
      - run-background-container

      - wait-for-server
      - run:
          name: Run integration tests
          shell: bash
          command: |
            # get full list of tests
            grep ^test integration-tests/tests.js | sed 's/.*"\(.*\)".*/\1/' > rundir/all-tests
            # split them using timing info
            TESTS=$(circleci tests split --split-by=timings --timings-type=testname rundir/all-tests)
            # concat them into a pattern (note: $TESTS is deliberately unquoted)
            PATTERN=$(printf -- "^%s$|" $TESTS)
            # remove last char
            PATTERN=${PATTERN%?}
            scripts/run-in-docker integration-tests/run.sh --pattern="$PATTERN"
      - assert-clean-worktree

      - extract-and-save-artifacts

  rust-integration-tests:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - restore_cache:
          keys:
            - v9-client-{{ checksum "client/package.json" }}
            - v9-client-{{ checksum "rundir/today-timestamp" }}
            - v9-client-{{ checksum "rundir/minus1-timestamp" }}
            - v9-client-{{ checksum "rundir/minus2-timestamp" }}
            - v9-client-{{ checksum "rundir/minus3-timestamp" }}
      - run:
          command: |
            set +ex
            du -hs *
            du -hs backend/*
            du -hs client/*
            du --human-readable --count --threshold=5M
      - rust-setup: { project: "queue-scheduler" }
      - copy-into-container
      - run-background-container
      - wait-for-server
      - run:
          name: Run queue-scheduler tests
          command: scripts/run-in-docker scripts/run-rust-tests queue-scheduler
      - assert-clean-worktree


  push-to-gcp:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - run:
          command: |
            set +ex
            du -hs *
            du -hs backend/*
            du --human-readable --count --threshold=5M
      - copy-into-container
      - run-background-container
      # Now that the workspaces have combined, we need to regenerate etags.json
      - wait-for-server
      - run: docker cp vols:/home/dark/app/backend/static/etags.json backend/static
      - run: scripts/run-in-docker scripts/gcp-build-containers
      - auth-with-gcp
      - run: scripts/run-in-docker scripts/push-assets-to-cdn
      - run: scripts/run-in-docker scripts/gcp-push-images-to-gcr
      # Save the image IDs for deployment later
      - run: |
          mkdir gcr-image-ids
          docker images gcr.io/balmy-ground-195100/dark-gcp -q | head -n 1 > gcr-image-ids/server
          docker images gcr.io/balmy-ground-195100/dark-gcp-qw -q | head -n 1 > gcr-image-ids/qw
          docker images gcr.io/balmy-ground-195100/dark-gcp-cron -q | head -n 1 > gcr-image-ids/cron
          docker images gcr.io/balmy-ground-195100/dark-gcp-stroller -q | head -n 1 > gcr-image-ids/stroller
          docker images gcr.io/balmy-ground-195100/dark-gcp-queue-scheduler -q | head -n 1 > gcr-image-ids/queue-scheduler
          docker images gcr.io/balmy-ground-195100/tunnel -q | head -n 1 > gcr-image-ids/tunnel
          docker images gcr.io/balmy-ground-195100/dark-gcp-postgres-honeytail -q | head -n 1 > gcr-image-ids/postgres-honeytail
      - persist_to_workspace:
          root: "."
          paths: [ gcr-image-ids ]


  deploy:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - copy-into-container
      - run-background-container
      - wait-for-container
      - auth-with-gcp
      - run: |
          scripts/run-in-docker scripts/gke-deploy       \
            --server-image-id=`cat gcr-image-ids/server` \
            --qw-image-id=`    cat gcr-image-ids/qw`     \
            --cron-image-id=`  cat gcr-image-ids/cron`   \
            --stroller-image-id=`cat gcr-image-ids/stroller` \
            --queue-scheduler-image-id=`cat gcr-image-ids/queue-scheduler` \
            --tunnel-image-id=`cat gcr-image-ids/tunnel` \
            --postgres-honeytail-image-id=`cat gcr-image-ids/postgres-honeytail`


workflows:
  version: 2
  build-and-deploy:
    jobs:
      # initial builds & tests
      - build-backend
      - build-client
      - build-queue-scheduler
      - build-stroller
      - build-postgres-honeytail
      - validate-honeycomb-config

      # expensive tests
      - rust-integration-tests:
          requires:
            - build-backend
            - build-client
            - build-queue-scheduler
      - integration-tests:
          requires:
            - build-backend
            - build-client

      # pre-deploy, in parallel with integration-tests
      - push-to-gcp:
          filters:
            branches:
              only: master
          requires:
            - build-backend
            - build-client
            - build-stroller
            - build-queue-scheduler
            - build-postgres-honeytail

      # actual deploy
      - deploy:
          filters:
            branches:
              only: master
          requires:
            - validate-honeycomb-config
            - integration-tests
            - rust-integration-tests
            - push-to-gcp
