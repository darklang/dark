version: 2.1

# There is a strong connection between this file and the equivalent files for
# running Dark in dev, which are scripts/builder and
# scripts/support/build-server. Generally, if you add something to this file,
# there's an equivalent to be added in one of those files.

executors:
  my-executor:
    docker:
      - image: docker:stable-git
  in-container:
    working_directory: ~/app
    environment:
      IN_DEV_CONTAINER: true
      # these keys are read-only
      AWS_ACCESS_KEY_ID: "AKIAXJAGP54V756YBAHZ"
      AWS_SECRET_ACCESS_KEY: "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"
    docker:
      - image: 500377317163.dkr.ecr.us-east-1.amazonaws.com/dark-ci:latest
  # Rust is so big we create a separate container for it and only use that
  # for rust builds
  in-rust-container:
    working_directory: ~/app
    environment:
      IN_DEV_CONTAINER: true
      # these keys are read-only
      AWS_ACCESS_KEY_ID: "AKIAXJAGP54V756YBAHZ"
      AWS_SECRET_ACCESS_KEY: "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"
    docker:
      - image: 500377317163.dkr.ecr.us-east-1.amazonaws.com/dark-ci:rust-latest


commands:

  # CircleCI won't share the "deploy key" used to checkout the repo with a branch
  # unless we've opted to share secrets, which we should never do. So this adds a
  # new read-only deploy key that can only be used to check out this repo 
  dark-checkout:
    steps:
      - run:
          environment:
            DARK_DEPLOY_KEY: "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"
          command: |
            mkdir -p ~/.ssh
            ls -la ~/.ssh
            echo "${DARK_DEPLOY_KEY}" | base64 -d > ~/.ssh/id_rsa
            echo "${DARK_DEPLOY_KEY}" | base64 -d > ~/debug
            ls -la ~/.ssh
            chmod 600 ~/.ssh/id_rsa
            md5sum ~/.ssh/id_rsa
      # CircleCI has a key in here already that it uses by default - remove it
      - run: ssh-add -D
      # Avoid "are you sure" prompt
      - run: echo 'github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==
' >> /home/dark/.ssh/known_hosts
      # Don't use CircleCI's built-in `checkout` command as it seems to add the key back
      - run: GIT_SSH_COMMAND='ssh -i /home/dark/.ssh/id_rsa -o /home/dark/.ssh/known_hosts' git clone git@github.com:darklang/dark
  show-large-files-and-directories:
    steps:
      - run:
          # show any file or directory over 50M in size
          # note alpine find doesn't support +50M here
          name: show large files and directories
          command: |
            find ~ -size +51200k -exec du -h {} \;
            du -ht 50M

  ##########################
  # Check the worktree
  ##########################
  assert-clean-worktree:
    steps:
      - run:
          name: Assert the worktree is clean
          command: "bash -c '[[ -z $(git status -s) ]] && echo Workdir is clean || { echo Workdir is not clean:; git status -s; $(exit 1); }'"


  ##########################
  # Setup app
  ##########################
  setup-app:
    steps:
      - run:
          name:
            Setup build environment
          command: |
            set -x
            scripts/support/setup-circleci-environment
            scripts/support/create-app-directories
            scripts/support/create-cache-directories
            scripts/support/setup-hosts
            scripts/support/start-background-services postgresql
            env

  ##########################
  # Rust
  ##########################
  rust-setup:
    parameters:
      project: { type: string }
    steps:
      - setup-app
      - restore_cache:
          keys:
            # This cache should be about 500MB or so. It balloons over time and needs to be deleted.
            - v0d-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}-{{ .Branch }}
            - v0d-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}
            - v0d-<< parameters.project >>

  rust-finish:
    parameters:
      project: { type: string }
    steps:
      - run:
          name: Reduce caches
          command: cargo cache -a
      - show-large-files-and-directories

      # must persist to workspace first, as next step will remove built release artifact
      - persist_to_workspace:
          root: "."
          paths: [ << parameters.project >>/target/release/dark-<< parameters.project >> ]

      # This removes files in the top-level of target/{debug,release}, which include the actual built artifact
      # and other intermediates that will always be rebuilt on the next build (so there's no sense in caching them).
      # It also includes our own (dark*) build files from deps, which are likewise always rebuilt.
      #
      # See https://github.com/rust-lang/cargo/issues/5885 for discussion and details
      - run:
          name: Cleanup frequently changing rust artifacts
          command: |
            find << parameters.project >>/target -maxdepth 2 -type f -delete
            rm -rf << parameters.project >>/target/{debug,release}/{deps,.fingerprint}/dark*

      # https://doc.rust-lang.org/nightly/cargo/guide/cargo-home.html#caching-the-cargo-home-in-ci
      - save_cache:
          name: "Save << parameters.project >> cache"
          paths:
            - << parameters.project >>/target
            - .cargo/bin/
            - .cargo/registry/index/
            - .cargo/registry/cache/
            - .cargo/git/db/
          key: v0d-<< parameters.project >>-{{ checksum "<< parameters.project >>/Cargo.lock" }}-{{ .Branch }}

  ##########################
  # Initializing the containers
  ##########################
  prep-container-creation:
    steps:
      - setup_remote_docker: { docker_layer_caching: true }

      # Save the docker env: type .docker-env when sshing in, then you can
      # use ./scripts/run-in-docker
      - run:
          name: Setup docker-env for debugging
          command: env | grep 'DOCKER\|NO_PROXY' | sed 's/^/export /' > ../docker-env

  build-gcp-containers:
    steps:
      - prep-container-creation
      - run:
          name: Regenerate combined ETags
          command: |
            scripts/support/generate-etags
            scripts/support/check-etags
            cp backend/static/etags.json rundir/
      - run: scripts/gcp-build-containers



  ##########################
  # misc
  ##########################
  auth-with-gcp:
    parameters: { background: { type: boolean } }
    steps:
      - run:
          name: Auth with GCP
          background: << parameters.background >>
          command: |
            echo $GCLOUD_SERVICE_KEY | base64 --decode --ignore-garbage > gcloud-service-key.json
            gcloud auth activate-service-account --key-file gcloud-service-key.json

##########################
# Actual workflow
##########################
jobs:
  build-client:
    executor: in-container
    steps:
      - dark-checkout
      - setup-app
      - restore_cache:
          keys:
            - v2-client-{{ checksum "yarn.lock" }}-{{ .Branch }}
            - v2-client-{{ checksum "yarn.lock" }}
            - v2-client
      - run: scripts/support/compile --test package.json client/src/styles/app.scss
      - assert-clean-worktree
      - run: scripts/support/shellchecker # run here cause its the fastest
      - show-large-files-and-directories
      - save_cache:
          name: "Save packagejson-specific cache"
          paths: [ "node_modules" ]
          key: v2-client-{{ checksum "yarn.lock" }}-{{ .Branch }}
      - persist_to_workspace:
          root: "."
          paths:
            - backend/static/
      - store_artifacts: { path: rundir }
      - store_artifacts: { path: backend/static/etags.json }
      - store_test_results: { path: rundir/test_results }

  build-backend:
    executor: in-container
    steps:
      - checkout
      - setup-app
      - restore_cache:
          keys:
            - v7-backend-{{ checksum "esy.json" }}
            - v7-backend
      # appsupport is needed for a unit test, but it is not needed as part
      # of the backend otherwise. It is compiled as part of the frontend
      # tests.
      - run: touch backend/static/appsupport.js
      - show-large-files-and-directories
      - run: scripts/support/compile --test esy.json
      - assert-clean-worktree
      # Doesn't need to be run post-build, but takes <1s to run
      - run: scripts/ocaml-find-unused backend/test
      - persist_to_workspace:
          # Do this before reducing size of cache
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - _build/default/backend/bin/server.exe
            - _build/default/backend/bin/emergency_login_script.exe
            - _build/default/backend/bin/queue_worker.exe
            - _build/default/backend/bin/cron_checker.exe
            - backend/static/analysis.js
      - run:
          name: Reduce size of esy cache
          command: |
            set -x
            rm -Rf /home/dark/.esy/3/b
            # It seems like everything builds and rebuilds fine without
            # these. Other files are needed: .o, .a, .cma, .cmx.
            shopt -s globstar
            rm -f /home/dark/.esy/3/i/**/*.cmt
            rm -f /home/dark/.esy/3/i/**/*.cmti
            rm -f /home/dark/.esy/3/i/**/*.byte
            rm -f /home/dark/.esy/3/i/**/*.cmxs
            # These can be very cheaply rebuilt, and are about 400MB
            rm -f /home/dark/app/_build/default/backend/*/*.exe
      - show-large-files-and-directories
      - save_cache:
          paths:
            - _build
            - node_modules
            - /home/dark/.esy
          key: v7-backend-{{ checksum "esy.json" }}
      - store_artifacts: { path: rundir }
      - store_test_results: { path: rundir/test_results }


  build-stroller:
    executor: in-rust-container
    steps:
      - checkout
      - rust-setup: { project: "stroller" }
      - run: scripts/support/compile stroller/Cargo.toml --test
      - assert-clean-worktree
      - rust-finish: { project: "stroller" }

  build-queue-scheduler:
    executor: in-rust-container
    steps:
      - checkout
      - rust-setup: { project: "queue-scheduler" }
      # tests are run in rust-integration-tests
      - run: scripts/support/compile queue-scheduler/Cargo.toml
      - assert-clean-worktree
      - rust-finish: { project: "queue-scheduler" }

  build-postgres-honeytail:
    executor: my-executor
    steps:
      - checkout
      - prep-container-creation
      - run: cd postgres-honeytail && docker build -t dark-gcp-postgres-honeytail .

  validate-honeycomb-config:
    executor: my-executor
    steps:
      - checkout
      - prep-container-creation
      - run: apk add --update bash jq python py-pip && pip install yq
      - run: bash -c scripts/support/test-honeycomb-config.sh

  integration-tests:
    executor: in-container
    parallelism: 4
    steps:
      - checkout
      - setup-app
      - attach_workspace: { at: "." }
      - restore_cache: # get testcafe
          keys:
            - v1d-client-{{ checksum "yarn.lock" }}-{{ .Branch }}
            - v1d-client-{{ checksum "yarn.lock" }}
            - v1d-client
      - show-large-files-and-directories
      - run:
          name: Run integration tests
          command: |
            scripts/support/generate-etags
            scripts/support/runserver

            # get full list of tests
            grep ^test integration-tests/tests.js | sed 's/.*"\(.*\)".*/\1/' > rundir/all-tests
            # split them using timing info
            TESTS=$(circleci tests split --split-by=timings --timings-type=testname rundir/all-tests)
            # concat them into a pattern (note: $TESTS is deliberately unquoted)
            PATTERN=$(printf -- "^%s$|" $TESTS)
            # remove last char
            PATTERN=${PATTERN%?}
            scripts/wait-until-server-ready
            integration-tests/run.sh --pattern="$PATTERN"
      - assert-clean-worktree
      - store_artifacts: { path: rundir }
      - store_test_results: { path: rundir/test_results }


  rust-integration-tests:
    executor: in-rust-container
    steps:
      - checkout
      - rust-setup: { project: "queue-scheduler" }
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - run:
          name: Trigger migrations with runserver
          command: |
            # Run the server long enough to ensure it runs the migrations
            scripts/support/generate-etags
            scripts/support/runserver
            scripts/wait-until-server-ready
      - run:
          name: Run queue-scheduler tests
          command: scripts/run-rust-tests queue-scheduler
      - assert-clean-worktree

  gcp-containers-test:
    executor: in-container
    steps:
      # Just test that we can build them for now
      - checkout
      - setup-app
      - attach_workspace: { at: "." }
      - build-gcp-containers

  push-to-gcp:
    executor: in-container
    steps:
      - checkout
      - setup-app
      - auth-with-gcp: { background: true }
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - build-gcp-containers
      - run: scripts/push-assets-to-cdn
      - run: scripts/gcp-push-images-to-gcr
      # Save the image IDs for deployment later
      - run:
          name: Save image IDs
          command: |
            mkdir gcr-image-ids
            time docker images gcr.io/balmy-ground-195100/dark-gcp -q | head -n 1 > gcr-image-ids/server
            time docker images gcr.io/balmy-ground-195100/dark-gcp-qw -q | head -n 1 > gcr-image-ids/qw
            time docker images gcr.io/balmy-ground-195100/dark-gcp-cron -q | head -n 1 > gcr-image-ids/cron
            time docker images gcr.io/balmy-ground-195100/dark-gcp-stroller -q | head -n 1 > gcr-image-ids/stroller
            time docker images gcr.io/balmy-ground-195100/dark-gcp-queue-scheduler -q | head -n 1 > gcr-image-ids/queue-scheduler
            time docker images gcr.io/balmy-ground-195100/tunnel -q | head -n 1 > gcr-image-ids/tunnel
            time docker images gcr.io/balmy-ground-195100/dark-gcp-postgres-honeytail -q | head -n 1 > gcr-image-ids/postgres-honeytail
      - persist_to_workspace:
          root: "."
          paths: [ gcr-image-ids ]


  deploy:
    executor: in-container
    steps:
      - checkout
      - setup-app
      - auth-with-gcp: { background: false }
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - run: |
          scripts/gke-deploy       \
            --server-image-id=`cat gcr-image-ids/server` \
            --qw-image-id=`    cat gcr-image-ids/qw`     \
            --cron-image-id=`  cat gcr-image-ids/cron`   \
            --stroller-image-id=`cat gcr-image-ids/stroller` \
            --queue-scheduler-image-id=`cat gcr-image-ids/queue-scheduler` \
            --tunnel-image-id=`cat gcr-image-ids/tunnel` \
            --postgres-honeytail-image-id=`cat gcr-image-ids/postgres-honeytail`
          scripts/honeymarker.sh


workflows:
  version: 2
  build-and-deploy:
    jobs:
      # initial builds & tests
      - build-postgres-honeytail
      - validate-honeycomb-config
      - build-backend
      - build-client
      - build-stroller
      - build-queue-scheduler

      # expensive tests
      - rust-integration-tests:
          requires:
            - build-backend
            - build-client
            - build-queue-scheduler
      - integration-tests:
          requires:
            - build-backend
            - build-client
      - gcp-containers-test:
          requires:
            - build-client # to rebuild etags
            - build-backend
            - build-stroller
            - build-queue-scheduler

      # pre-deploy, in parallel with integration-tests
      - push-to-gcp:
          filters:
            branches:
              only: master
          requires:
            - build-backend
            - build-client
            - build-stroller
            - build-queue-scheduler
            - build-postgres-honeytail

      # actual deploy
      - deploy:
          filters:
            branches:
              only: master
          requires:
            - validate-honeycomb-config
            - integration-tests
            - rust-integration-tests
            - push-to-gcp
