version: 2.1

# Config for CI/CD pipeline

# There is a strong connection between this file and the equivalent files for
# running Dark in dev, which are scripts/builder and
# scripts/build/_build-server. Generally, if you add something to this file,
# there's an equivalent to be added in one of those files.

executors:
  simple-executor:
    docker:
      - image: cimg/base:2023.06
  in-container:
    working_directory: ~/app
    environment:
      IN_DEV_CONTAINER: true
    docker:
      # DOCKERFILE_REPO: see Dockerfile note about how this is built.
      - image: darklang/dark-base:466eee2

commands:
  show-large-files-and-directories:
    steps:
      - run:
          # show any file or directory over 50M in size
          # note alpine find doesn't support +50M here
          name: show large files and directories
          command: |
            find ~ -size +51200k -exec du -h {} \;
            du -ht 50M

  ##########################
  # Check the worktree
  ##########################
  assert-clean-worktree:
    steps:
      - run:
          name: Assert the worktree is clean
          command: "bash -c '[[ -z $(git status -s) ]] && echo Workdir is clean || { echo Workdir is not clean:; git status -s; $(exit 1); }'"

  ##########################
  # Checkout - need to remove some things for a clean checkout
  ##########################
  darkcheckout:
    steps:
      # To get ownership right when mounting volumes in local development, the
      # container adds a bunch of directories within ~/app. However, in Circle,
      # we don't use volumes and the container is loaded before the git
      # checkout, which complains if the checkout directory is not empty. So
      # let's delete those first.
      - run: rm -Rf /home/dark/app/*
      - checkout

  ##########################
  # Setup app
  ##########################
  setup-app:
    steps:
      - run:
          name: Setup build environment
          command: |
            set -x
            scripts/devcontainer/_setup-circleci-environment
            scripts/devcontainer/_create-app-directories
            scripts/devcontainer/_create-cache-directories
            scripts/devcontainer/_setup-hosts
            scripts/devcontainer/_start-background-services postgresql
            env

  ##########################
  # Deploy locks
  ##########################
  deploy-lock-remove-on-fail:
    steps:
      - run:
          name: Remove deploy lock
          when: on_fail
          command: |
            if [[ "${CIRCLE_BRANCH}" = "main" ]]; then
              ./scripts/deployment/deploy-lock-one-remove
            fi

  ##########################
  # Slack
  ##########################
  slack-notify-failure:
    parameters:
      buildType: { type: string } # build or deploy
    steps:
      - run:
          name: Slack notification
          when: on_fail
          command: |
            curl -v -X POST -H 'Content-type: application/json' -d "{ \"success\": false, \"buildType\": \"<<parameters.buildType>>\", \"branch\": \"$CIRCLE_BRANCH\", \"url\": \"$CIRCLE_BUILD_URL\", \"prs\": \"$CIRCLE_PULL_REQUESTS\", \"sha\": \"$CIRCLE_SHA1\", \"username\": \"$CIRCLE_USERNAME\", \"job\": \"$CIRCLE_JOB\" }" https://ops-circleci.builtwithdark.com/notify-slack

  slack-notify-success:
    parameters:
      buildType: { type: string } # build or deploy
    steps:
      - run:
          name: Slack notification
          when: on_success
          command: |
            curl -v -X POST -H 'Content-type: application/json' -d "{ \"success\": true, \"buildType\": \"<<parameters.buildType>>\", \"branch\": \"$CIRCLE_BRANCH\", \"url\": \"$CIRCLE_BUILD_URL\", \"prs\": \"$CIRCLE_PULL_REQUESTS\", \"sha\": \"$CIRCLE_SHA1\", \"username\": \"$CIRCLE_USERNAME\", \"job\": \"$CIRCLE_JOB\" }" https://ops-circleci.builtwithdark.com/notify-slack

  slack-notify-job-failure:
    steps:
      - slack-notify-failure:
          buildType: "job"
  slack-notify-deploy:
    steps:
      - slack-notify-failure:
          buildType: "deploy"
      - slack-notify-success:
          buildType: "deploy"
  slack-notify-build:
    steps:
      - slack-notify-failure:
          buildType: "build"
      - slack-notify-success:
          buildType: "build"

  ##########################
  # Initializing the containers
  ##########################
  prep-container-creation:
    steps:
      - setup_remote_docker: { docker_layer_caching: true, version: 20.10.18 }

      # Save the docker env: type .docker-env when sshing in, then you can
      # use ./scripts/run-in-docker
      - run:
          name: Setup docker-env for debugging
          command: env | grep 'DOCKER\|NO_PROXY' | sed 's/^/export /' > ../docker-env

  build-gcp-containers:
    steps:
      - run: echo TODO
      - prep-container-creation
      # LIGHTTODO build containers
      # - run: scripts/deployment/shipit containers build --save-manifest=gcr-image-ids.json
      - run: cat gcr-image-ids.json
      # Test them
      # - run: scripts/deployment/shipit release prepare --arg CHANGE_CAUSE="test" --manifest=gcr-image-ids.json

  ##########################
  # Google Cloud
  # https://circleci.com/docs/openid-connect-tokens/#setting-up-gcp
  ##########################
  auth-with-gcp:
    parameters: { background: { type: boolean } }
    steps:
      - run:
          name: Auth with GCP
          background: << parameters.background >>
          command: |
            # Don't run a second time (no need, but also token becomes invalid after an hour)
            if [[ ! -f CIRCLE_OIDC_TOKEN_FILE ]]; then
              echo $CIRCLE_OIDC_TOKEN > CIRCLE_OIDC_TOKEN_FILE
              gcloud auth login --brief --cred-file .circleci/gcp-workload-identity-config.json
            fi

  auth-gcr:
    steps:
      - run:
          name: Auth with GCR
          command: |
            gcloud auth configure-docker

##########################
# Actual workflow
##########################
jobs:

  # Build server binaries and run tests
  build-backend:
    executor: in-container
    resource_class: xlarge
    steps:
      - darkcheckout
      # Set the timestamp to the commit time. This allows timestamp-based build tools
      # like .NET to use their incremental build feature. Without this, the checkout
      # time is always newer than the cached object file, and files are always
      # rebuilt
      # Currently disabled, as it was causing issues failures within
      # Serialization.Tests.fs where the allowedTypes for serializers did not match
      # what tests expected (and what files were persisted in backend/serialization).
      # TODO: think through an alternative or more nuanced approach.
      #- run: git restore-mtime
      - setup-app
      # The date is used to get a fresh cache each week
      - run: shasum backend/paket.lock backend/global.json <(date +"%U%Y") > ../checksum
      - restore_cache:
          keys:
            - v1-backend-{{ checksum "../checksum" }}
            # Fails often enough that it's better not to have a fallback
      - show-large-files-and-directories
      # For tests
      - run: ./scripts/build/_dotnet-wrapper tool restore
      - run: ./scripts/build/_dotnet-wrapper paket restore
      # DebugType=None and DebugSymbol=false tells dotnet not to copy .pdb files to publish/
      - run: ./scripts/build/_dotnet-wrapper publish -c Release fsdark.sln /p:DebugType=None /p:DebugSymbols=false
      - run: scripts/run-backend-tests --published
      - assert-clean-worktree
      - persist_to_workspace:
          root: "."
          paths:
            # Just enough for deploy
            - backend/Build/out/BwdServer/Release/net7.0/linux-x64/publish/BwdServer
            # - backend/Build/out/QueueWorker/Release/net7.0/linux-x64/publish/QueueWorker
            # - backend/Build/out/CronChecker/Release/net7.0/linux-x64/publish/CronChecker
            - backend/Build/out/ProdExec/Release/net7.0/linux-x64/publish/ProdExec
      - show-large-files-and-directories
      - save_cache:
          paths:
            - backend/Build/obj
            - /home/dark/.nuget
          key: v1-backend-{{ checksum "../checksum" }}
      - store_artifacts: { path: rundir }
      - store_test_results: { path: rundir/test_results }
      - slack-notify-job-failure
      - deploy-lock-remove-on-fail


  static-checks:
    executor: in-container
    steps:
      - darkcheckout
      - run: scripts/linting/shellchecker
      # There are currently no yaml files
      # - run: scripts/linting/yamllinter
      # LIGHTTODO check terraform
      - run: scripts/formatting/format check
      - slack-notify-job-failure
      - deploy-lock-remove-on-fail

  gcp-containers-test:
    executor: in-container
    steps:
      # Just test that we can build them for now
      - darkcheckout
      - setup-app
      - attach_workspace: { at: "." }
      - build-gcp-containers
      - slack-notify-job-failure
      - deploy-lock-remove-on-fail

  push-containers-to-gcp:
    executor: in-container
    steps:
      - darkcheckout
      - setup-app
      - auth-with-gcp: { background: true }
      - auth-gcr
      - attach_workspace: { at: "." }
      - show-large-files-and-directories
      - build-gcp-containers
      - persist_to_workspace:
          root: "."
          paths: ["gcr-image-ids.json"]
      # LIGHTTODO push containers
      # - run: scripts/deployment/shipit containers push
      - slack-notify-job-failure
      - deploy-lock-remove-on-fail

  deploy-lock:
    # Note that it doesn't matter if the in-container executor is a bit slow: they
    # deploy according the timestamp on the commit. Even if builds add their locks in
    # the wrong order, so long as the locks are there by the time the next deploy
    # comes, they'll be in the right order.
    executor: in-container
    steps:
      - darkcheckout
      - run: scripts/deployment/deploy-lock-one-add
      - slack-notify-job-failure
      - deploy-lock-remove-on-fail

  deploy:
    executor: in-container
    steps:
      - run: echo TODO
      # LIGHTTODO
      - darkcheckout
      - setup-app
      # - auth-with-gcp: { background: false }
      # - attach_workspace: { at: "." }
      - show-large-files-and-directories
      # LIGHTTODO
      # # deploy lock is removed as part of the gke-deploy script
      - run: ./scripts/deployment/deploy-lock-one-remove
      # # - run: scripts/deployment/gke-deploy --manifest=gcr-image-ids.json
      - slack-notify-deploy
      - deploy-lock-remove-on-fail

  notify-non-deploy:
    executor: simple-executor
    steps:
      - slack-notify-build

workflows:
  build-and-deploy:
    jobs:
      # initial builds & tests
      - static-checks
      - build-backend

      - gcp-containers-test:
          # This is fully covered by push-containers-to-gcp, so no need to do it twice
          filters:
            branches:
              ignore: main
          requires:
            - build-backend

      - push-assets-to-gcp:
          context:
            - gcp context
          filters:
            branches:
              only: main
          requires:
            - build-backend

      - push-containers-to-gcp:
          context:
            - gcp context
          filters:
            branches:
              only: main
          requires:
            - build-backend

      # actual deploy
      - deploy:
          context:
            - gcp context
          filters:
            branches:
              only: main
          requires:
            - deploy-lock
            - push-containers-to-gcp
            - push-assets-to-gcp
            - static-checks

      - deploy-lock:
          filters:
            branches:
              only: main

      - notify-non-deploy:
          filters:
            branches:
              ignore: main
          requires:
            - build-backend
            - gcp-containers-test
            - static-checks
