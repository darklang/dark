version: 2.1
executors:
  my-executor:
    docker:
      - image: docker:stable-git

commands:
  ##########################
  # Getting into the remote container
  ##########################
  copy-into-container:
    steps:
      # https://circleci.com/docs/2.0/building-docker-images/#mounting-folders
      - run:
          name: Copy app directory into dev container
          command: |
            docker create -v /home/dark/app --name vols alpine:3.4 /bin/true
            docker cp . vols:/home/dark/app
            # set the ownership of all this
            docker run -i --volumes-from vols alpine sh -c "adduser -D -u 1000 dark; chown -R dark /home/dark/app"

  ##########################
  # Artifacts
  ##########################
  extract-and-save-artifacts:
    steps:
      - run:
          name: Copy out artifacts
          when: always
          command: |
            mkdir -p artifacts
            docker cp vols:/home/dark/app/rundir artifacts/rundir
            docker cp vols:/home/dark/app/backend/static/etags.json artifacts/
            ls -la backend/static > artifacts/asset-list.txt
      - store_artifacts:
          path: artifacts
      - store_test_results:
          path: artifacts/rundir/test_results


  ##########################
  # Caches
  ##########################
  clean-caches:
    parameters:
      path:
        type: string
    steps:
      - run:
          name: maybe clear caches
          # since we don't checksum the cache on its contents, it may
          # continue to grow. as a result, let's clear the cache weekly.
          # we store the day the cache was built in the cache. if the
          # cache was built on friday, and today is not friday, then
          # it's the first build after last week, and clear it.
          command: |
            if [[ `date +"%a"` != "friday" && `cat << parameters.path >>/cache_day` == "friday" ]]; then
              echo "clearing caches"
              rm -rf << parameters.path >>
            else
              echo "not clearing caches"
            fi
            mkdir -p << parameters.path >>
            date +"%a" > << parameters.path >>/cache_day

  ##########################
  # Initializing the containers
  ##########################
  initialize:
    steps:
      - setup_remote_docker:
          docker_layer_caching: true

      # Save the docker env: type .docker-env when sshing in, then you can
      # use ./scripts/run-in-docker
      - run: |
          env \
          | grep 'DOCKER\|NO_PROXY' \
          | sed 's/^/export /' \
          > /root/docker-env

      - run:
          name: Install outer container utilities
          # coreutils for gnu date
          command: |
            apk add --update bash coreutils nginx jq

      - run:
          name: "Setup cache names"
          command: |
            date +"%F" > today-timestamp
            date +"%F" -d "today - 1 days" > minus1-timestamp
            date +"%F" -d "today - 2 days" > minus2-timestamp
            date +"%F" -d "today - 3 days" > minus3-timestamp


  ##########################
  # misc
  ##########################
  run-background-container:
    steps:
      - run:
          name: Build container if necessary
          command: scripts/builder
      - run:
          name: Run background container
          command: scripts/builder --ci-serve
          background: true
  wait-for-container:
    steps:
      - run:
          name: "Wait for container"
          command: |
            # --foreground because this is run in a script by circle
            timeout --foreground 5m scripts/wait-until-container-ready
  wait-for-server:
    steps:
      - wait-for-container
      - run:
          name: "Wait for server"
          command: |
            # --foreground because this is run in a script by circle
            timeout --foreground 5m scripts/wait-until-server-ready
  auth-with-gcp:
    steps:
      - run:
          name: Auth with GCP
          command: |
            echo $GCLOUD_SERVICE_KEY | base64 --decode --ignore-garbage > gcloud-service-key.json
            docker cp gcloud-service-key.json dark-dev:/home/dark/app/gcloud-service-key.json
            scripts/run-in-docker gcloud auth activate-service-account --key-file /home/dark/app/gcloud-service-key.json

##########################
# Actual workflow
##########################
jobs:
  build-stroller:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v10-stroller-{{ checksum "stroller/Cargo.lock" }}
            - v10-stroller-{{ checksum "today-timestamp" }}
            - v10-stroller-{{ checksum "minus1-timestamp" }}
            - v10-stroller-{{ checksum "minus2-timestamp" }}
            - v10-stroller-{{ checksum "minus3-timestamp" }}
      - clean-caches: { path: "stroller/target" }
      - clean-caches: { path: "cargo" }
      - run:
          name: Set up volume for cargo
          command: |
            docker create -v /usr/local/cargo --name dark_rust_cargo alpine:3.4 /bin/true
            docker cp cargo dark_rust_cargo:/usr/local/cargo
            docker run -i --volumes-from dark_rust_cargo alpine sh -c "adduser -D -u 1000 dark; chown -R dark /usr/local/cargo"
            rm -Rf cargo
      - copy-into-container
      - run: scripts/builder --compile-stroller --test
      - run:
          name: Copy out generated files and caches
          command: |
            docker cp vols:/home/dark/app/stroller/target stroller/
            docker cp dark_rust_cargo:/usr/local/cargo cargo
      - save_cache:
          name: "Save cargolock-specific stroller cache"
          paths:
            - stroller/target
            - cargo
          key: v10-stroller-{{ checksum "stroller/Cargo.lock" }}
      - save_cache:
          name: "Save daily stroller cache"
          paths:
            - stroller/target
            - cargo
          key: v10-stroller-{{ checksum "today-timestamp" }}
      - persist_to_workspace:
          root: "."
          paths:
            # Just enough for deploy
            - stroller/target/release/dark-stroller


  build-backend:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v6-backend-{{ checksum "today-timestamp" }}
            - v6-backend-{{ checksum "minus1-timestamp" }}
            - v6-backend-{{ checksum "minus2-timestamp" }}
            - v6-backend-{{ checksum "minus3-timestamp" }}
      - clean-caches: { path: "backend/_build" }
      # appsupport is needed for a unit test
      - run: touch backend/static/appsupport.js
      - copy-into-container
      - run: scripts/builder --compile-backend --test
      - run:
          name: Copy out generated files and caches
          command: |
            docker cp vols:/home/dark/app/backend/_build backend/
            docker cp vols:/home/dark/app/backend/static/. backend/static
      - save_cache:
          name: "Save daily backend cache"
          paths: [ "backend/_build" ]
          key: v6-backend-{{ checksum "today-timestamp" }}
      - persist_to_workspace:
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - backend/_build/default/bin
            - backend/static/analysis.js
      - run:
          name: Copy out artifacts
          when: always
          command: |
            mkdir -p artifacts
            docker cp vols:/home/dark/app/rundir artifacts/rundir
      - store_artifacts:
          path: artifacts
      - store_test_results:
          path: artifacts/rundir/test_results

  build-postgres-honeytail:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v6-postgres-honeytail-{{ checksum "today-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "minus1-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "minus2-timestamp" }}
            - v6-postgres-honeytail-{{ checksum "minus3-timestamp" }}
      - run: cd postgres-honeytail && docker build -t dark-gcp-postgres-honeytail . && docker run -t dark-gcp-postgres-honeytail python test_logs.py

  build-client:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - restore_cache:
          keys:
            - v6-client-{{ checksum "client/package.json" }}
            - v6-client-{{ checksum "today-timestamp" }}
            - v6-client-{{ checksum "minus1-timestamp" }}
            - v6-client-{{ checksum "minus2-timestamp" }}
            - v6-client-{{ checksum "minus3-timestamp" }}
      - clean-caches: { path: "client/node_modules" }
      - clean-caches: { path: "client/lib" }
      - copy-into-container
      - run: scripts/builder --compile-client --test
      - run-background-container
      - wait-for-container
      - run: scripts/support/shellchecker # run here cause its the fastest
      - run:
          name: Copy out generated files and caches
          command: |
            docker cp vols:/home/dark/app/client/node_modules client
            docker cp vols:/home/dark/app/client/lib client
            docker cp vols:/home/dark/app/backend/static/. backend/static
      - save_cache:
          name: "Save packagejson-specific cache"
          paths: [ "client/node_modules" ]
          key: v6-client-{{ checksum "client/package.json" }}
      - save_cache:
          name: "Save daily client cache"
          paths: [ "client/node_modules" ]
          key: v6-client-{{ checksum "today-timestamp" }}
      - persist_to_workspace:
          root: "."
          paths:
            # Just enough for integration tests and deploy
            - backend/static/app.css
            - backend/static/app.js
            - backend/static/appsupport.js
            - backend/static/tracefetcher.js
            - backend/static/analysiswrapper.js
      - run:
          name: Copy out artifacts
          when: always
          command: |
            mkdir -p artifacts
            docker cp vols:/home/dark/app/rundir artifacts/rundir
            cp backend/static/etags.json artifacts
            ls -la backend/static > artifacts/asset-list.txt
      - store_artifacts:
          path: artifacts
      - store_test_results:
          path: artifacts/rundir/test_results



  integration-tests:
    executor: my-executor
    parallelism: 4
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - restore_cache: # get testcafe
          keys:
            - v6-client-{{ checksum "client/package.json" }}
            - v6-client-{{ checksum "today-timestamp" }}
            - v6-client-{{ checksum "minus1-timestamp" }}
            - v6-client-{{ checksum "minus2-timestamp" }}
            - v6-client-{{ checksum "minus3-timestamp" }}
      - copy-into-container
      - run-background-container

      # run this here so we save a little time waiting for the server to be ready.
      - run: nginx -t -c $(pwd)/scripts/support/nginx-toplevel.conf -g "pid $(pwd)/rundir/nginx.pid;"

      - wait-for-server
      - run:
          name: Run integration tests
          shell: bash
          command: |
            # get full list of tests
            grep ^test integration-tests/tests.js | sed "s/.*'\(.*\)'.*/\1/" > all-tests
            # split them using timing info
            TESTS=$(circleci tests split --split-by=timings --timings-type=testname all-tests)
            # concat them into a pattern (note: $TESTS is deliberately unquoted)
            PATTERN=$(printf -- "^%s$|" $TESTS)
            # remove last char
            PATTERN=${PATTERN%?}
            scripts/run-in-docker integration-tests/run.sh --pattern="$PATTERN"

      - extract-and-save-artifacts

  push-to-gcp:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - copy-into-container
      - run-background-container
      # Now that the workspaces have combined, we need to regenerate etags.json
      - wait-for-server
      - run: docker cp vols:/home/dark/app/backend/static/etags.json backend/static
      - run: scripts/run-in-docker scripts/gcp-build-containers
      - auth-with-gcp
      - run: scripts/run-in-docker scripts/push-assets-to-cdn
      - run: scripts/run-in-docker scripts/gcp-push-images-to-gcr
      # Save the image IDs for deployment later
      - run: |
          mkdir gcr-image-ids
          docker images gcr.io/balmy-ground-195100/dark-gcp -q | head -n 1 > gcr-image-ids/server
          docker images gcr.io/balmy-ground-195100/dark-gcp-qw -q | head -n 1 > gcr-image-ids/qw
          docker images gcr.io/balmy-ground-195100/dark-gcp-cron -q | head -n 1 > gcr-image-ids/cron
          docker images gcr.io/balmy-ground-195100/dark-gcp-stroller -q | head -n 1 > gcr-image-ids/stroller
          docker images gcr.io/balmy-ground-195100/tunnel -q | head -n 1 > gcr-image-ids/tunnel
          docker images gcr.io/balmy-ground-195100/dark-gcp-postgres-honeytail -q | head -n 1 > gcr-image-ids/postgres-honeytail
      - persist_to_workspace:
          root: "."
          paths: [ gcr-image-ids ]


  deploy:
    executor: my-executor
    steps:
      - checkout
      - initialize
      - attach_workspace: { at: "." }
      - copy-into-container
      - run-background-container
      - wait-for-container
      - auth-with-gcp
      - run: |
          scripts/run-in-docker scripts/gke-deploy       \
            --server-image-id=`cat gcr-image-ids/server` \
            --qw-image-id=`    cat gcr-image-ids/qw`     \
            --cron-image-id=`  cat gcr-image-ids/cron`   \
            --stroller-image-id=`cat gcr-image-ids/stroller` \
            --tunnel-image-id=`cat gcr-image-ids/tunnel` \
            --postgres-honeytail-image-id=`cat gcr-image-ids/postgres-honeytail`


workflows:
  version: 2
  build-and-deploy:
    jobs:
      # initial builds & tests
      - build-backend
      - build-client
      - build-stroller
      - build-postgres-honeytail

      # expensive tests
      - integration-tests:
          requires:
            - build-backend
            - build-client

      # pre-deploy, in parallel with integration-tests
      - push-to-gcp:
          filters:
            branches:
              only: master
          requires:
            - build-backend
            - build-client
            - build-stroller
            - build-postgres-honeytail

      # actual deploy
      - deploy:
          filters:
            branches:
              only: master
          requires:
            - integration-tests
            - push-to-gcp
