#!/usr/bin/env bash

. ./scripts/support/assert-in-container "$0" "$@"

set -euo pipefail

# Defaults
DARK_CLUSTER_REGION="us-west1"
DARK_CLUSTER_PROJECT="balmy-ground-195100"
DARK_CLUSTER="darkcluster$(date +"%s")"
DARK_CLUSTER_NUM_NODES="4"
DARK_CLUSTER_VERSION="1.11.7-gke.6"
DARK_CLUSTER_CLOUDSQL_USER="postgres"
DARK_CLUSTER_CLOUDSQL_PASS="6gCtEAKElJFpNCdw"

HELP="$(cat <<EOF
Usage: $0 REQUIRED_ARGS [OPTIONS]

A script that deploys a Dark-production-like cluster to Google Kubernetes Engine.

If you're tempted to move the static IPs from the old cluster to a new one generate
with this script, try it out a few times outside of production first. Moving the
static IPs the obvious way is flaky and seems nondeterministic. You may have better
luck swapping DNS if you need it and can live with the long propagation times.

Secrets:

NOTE: All secrets default to copying the credentials from the current cluster as per
their suggestion.

  --bwd-tls-crt=...      A base64-encoded TLS .crt file to use for the TLS-enabled ingress
                         serving darklang.com.
                         You can swipe creds from the current cluster with something like
                         the following:
                           kubectl get secrets bwd-tls -o json | jq -r '.data["tls.crt"]'
  --bwd-tls-key=...      A base64-encoded TLS .key file to use for the TLS-enabled ingress
                         serving builtwithdark.com.
                         You can swipe creds from the current cluster with something like
                         the following:
                           kubectl get secrets bwd-tls -o json | jq -r '.data["tls.key"]'
  --dl-tls-crt=...       A base64-encoded TLS .crt file to use for the TLS-enabled ingress
                         serving darklang.com.
                         You can swipe creds from the current cluster with something like
                         the following:
                           kubectl get secrets darklang-tls -o json | jq -r '.data["tls.crt"]'
  --dl-tls-key=...       A base64-encoded TLS .key file to use for the TLS-enabled ingress
                         serving darklang.com.
                         You can swipe creds from the current cluster with something like
                         the following:
                           kubectl get secrets darklang-tls -o json | jq -r '.data["tls.key"]'
  --cloudsql-creds=...   A base64-encoded JSON document including credentials for the cloudsql
                         instance. You can swipe creds from the current cluster with something
                         like the following:
                           kubectl get secret cloudsql-instance-credentials -o json \
                             | jq -r '.data["credentials.json"]'
  --assets-creds=...     A base64-encoded JSON document including credentials for uploading
                         to the dark-static-assets bucket. You can swipe creds from the
                         current cluster with something like the following:
                           kubectl get secret dark-static-assets -o json \
                             | jq -r '.data["balmy-ground-195100-d9b0f3de3013.json"]'

Other Options:

  --region=...           The Google cloud region to deploy into (default $DARK_CLUSTER_REGION).
  --project=...          The Google cloud project to deploy into (default $DARK_CLUSTER_PROJECT).
  --cluster=...          The name of the new cluster (default is to append unix time to
                         'darkcluster', a la $DARK_CLUSTER).
  --num-nodes=...        The number of nodes *per zone* in the cluster. GKE default is to deploy
                         to three zones, so the actual number of deployed nodes will be 3x this
                         amount (default $DARK_CLUSTER_NUM_NODES).
  --version=...          The Kubernetes version to run on the master and nodes. New versions are
                         released and old versions are obsoleted on GKE quickly, so you will
                         probably need to find the newest version (default $DARK_CLUSTER_VERSION).
  --cloudsql-user=...    The username for the cloudsql DB (default $DARK_CLUSTER_CLOUDSQL_USER).
  --cloudsql-pass=...    The password for the cloudsql DB (default $DARK_CLUSTER_CLOUDSQL_PASS)
  --help                 Display this menu.

EOF
)"


for i in "$@"
do
  case "${i}" in
    --region=*)
      DARK_CLUSTER_REGION="${i/--region=/''}"
      ;;
    --project=*)
      DARK_CLUSTER_PROJECT="${i/--project=/''}"
      ;;
    --cluster=*)
      DARK_CLUSTER="${i/--cluster=/''}"
      ;;
    --num-nodes=*)
      DARK_CLUSTER_NUM_NODES="${i/--num-nodes=/''}"
      ;;
    --version=*)
      DARK_CLUSTER_VERSION="${i/--version=/''}"
      ;;
    --cloudsql-user=*)
      DARK_CLUSTER_CLOUDSQL_USER="${i/--cloudsql-user=/''}"
      ;;
    --cloudsql-pass=*)
      DARK_CLUSTER_CLOUDSQL_PASS="${i/--cloudsql-pass=/''}"
      ;;
    --bwd-tls-crt=*)
      DARK_CLUSTER_BWD_TLS_CRT="${i/--bwd-tls-crt=/''}"
      ;;
    --bwd-tls-key=*)
      DARK_CLUSTER_BWD_TLS_KEY="${i/--bwd-tls-key=/''}"
      ;;
    --dl-tls-crt=*)
      DARK_CLUSTER_DL_TLS_CRT="${i/--dl-tls-crt=/''}"
      ;;
    --dl-tls-key=*)
      DARK_CLUSTER_DL_TLS_KEY="${i/--dl-tls-key=/''}"
      ;;
    --cloudsql-creds=*)
      DARK_CLUSTER_CLOUDSQL_INSTANCE_CREDS="${i/--cloudsql-creds=/''}"
      ;;
    --assets-creds=*)
      DARK_CLUSTER_STATIC_ASSETS_CREDS="${i/--assets-creds=/''}"
      ;;
    --help)
      echo "$HELP"
      exit 0
      ;;
    *)
      echo "Unexpected argument: $i"
      echo "$HELP"
      exit 1
      ;;
  esac
done

function print_step () {
  tput setab 6 && echo "=>" "$@" && tput sgr0
}

if [ ! -v DARK_CLUSTER_BWD_TLS_KEY ] || [ ! -v DARK_CLUSTER_BWD_TLS_CRT ] \
     || [ ! -v DARK_CLUSTER_DL_TLS_KEY ] || [ ! -v DARK_CLUSTER_DL_TLS_CRT ] \
     || [ ! -v DARK_CLUSTER_CLOUDSQL_INSTANCE_CREDS ]; then
  print_step "authorizing with the current cluster"
  gcloud container clusters get-credentials "projects/${DARK_CLUSTER_PROJECT}/zones/${DARK_CLUSTER_REGION}/clusters/$(< current-cluster)" --region=${DARK_CLUSTER_REGION}

  if [ ! -v DARK_CLUSTER_BWD_TLS_KEY ]; then
    print_step "Fetching DARK_CLUSTER_BWD_TLS_KEY"
    DARK_CLUSTER_BWD_TLS_KEY=$(kubectl get secrets bwd-tls -o json | jq -r '.data["tls.key"]')
  fi

  if [ ! -v DARK_CLUSTER_BWD_TLS_CRT ]; then
    print_step "Fetching DARK_CLUSTER_BWD_TLS_CRT"
    DARK_CLUSTER_BWD_TLS_CRT=$(kubectl get secrets bwd-tls -o json | jq -r '.data["tls.crt"]')
  fi

  if [ ! -v DARK_CLUSTER_DL_TLS_KEY ]; then
    print_step "Fetching DARK_CLUSTER_DL_TLS_KEY"
    DARK_CLUSTER_DL_TLS_KEY=$(kubectl get secrets darklang-tls -o json | jq -r '.data["tls.key"]')
  fi

  if [ ! -v DARK_CLUSTER_DL_TLS_CRT ]; then
    print_step "Fetching DARK_CLUSTER_DL_TLS_CRT"
    DARK_CLUSTER_DL_TLS_CRT=$(kubectl get secrets darklang-tls -o json | jq -r '.data["tls.crt"]')
  fi

  if [ ! -v DARK_CLUSTER_CLOUDSQL_INSTANCE_CREDS ]; then
    print_step "Fetching DARK_CLUSTER_CLOUDSQL_INSTANCE_CREDS"
    DARK_CLUSTER_CLOUDSQL_INSTANCE_CREDS=$(kubectl get secret cloudsql-instance-credentials -o json | jq -r '.data["credentials.json"]')
  fi

  if [ ! -v DARK_CLUSTER_STATIC_ASSETS_CREDS ]; then
    print_step "Fetching DARK_CLUSTER_STATIC_ASSETS_CREDS"
    DARK_CLUSTER_STATIC_ASSETS_CREDS=$(kubectl get secret dark-static-assets -o json | jq -r '.data["balmy-ground-195100-d9b0f3de3013.json"]')
  fi
fi


print_step "starting a new cluster named $DARK_CLUSTER"

gcloud beta container clusters create "$DARK_CLUSTER" \
  "--num-nodes=${DARK_CLUSTER_NUM_NODES}" \
  "--zone=${DARK_CLUSTER_REGION}" \
  "--project=${DARK_CLUSTER_PROJECT}" \
  "--cluster-version=${DARK_CLUSTER_VERSION}" \
  --enable-stackdriver-kubernetes \
  --enable-autorepair \
  --enable-network-policy

print_step "getting creds for the new cluster"
# It's very important you don't forget to switch the kube context here!!!
gcloud container clusters get-credentials "projects/${DARK_CLUSTER_PROJECT}/zones/${DARK_CLUSTER_REGION}/clusters/${DARK_CLUSTER}" --region=${DARK_CLUSTER_REGION}

print_step "installing secrets"
# add tls secrets
kubectl create -f - <<EOF
{
  "apiVersion": "v1",
  "kind": "Secret",
  "type": "kubernetes.io/tls",
  "data": {
    "tls.crt": "$DARK_CLUSTER_BWD_TLS_CRT",
    "tls.key": "$DARK_CLUSTER_BWD_TLS_KEY"
  },
  "metadata": {
        "name": "bwd-tls"
  }
}
EOF
kubectl create -f - <<EOF
{
  "apiVersion": "v1",
  "kind": "Secret",
  "type": "kubernetes.io/tls",
  "data": {
    "tls.crt": "$DARK_CLUSTER_DL_TLS_CRT",
    "tls.key": "$DARK_CLUSTER_DL_TLS_KEY"
  },
  "metadata": {
        "name": "darklang-tls"
  }
}
EOF

# add secrets for the cloudsql proxy service account
# printf | base64 here because, unlike the rest of the secrets,
# this username and password are sensitive to trailing whitespace.
kubectl create -f - <<EOF
{
  "apiVersion": "v1",
  "kind": "Secret",
  "type": "Opaque",
  "data": {
    "username": "$(printf "%s" "$DARK_CLUSTER_CLOUDSQL_USER" | base64)",
    "password": "$(printf "%s" "$DARK_CLUSTER_CLOUDSQL_PASS" | base64)"
  },
  "metadata": {
    "name": "cloudsql-db-credentials"
  }
}
EOF

# cloudsql instance creds
kubectl create -f - <<EOF
{
  "apiVersion": "v1",
  "kind": "Secret",
  "type": "Opaque",
  "data": {
    "credentials.json": "$DARK_CLUSTER_CLOUDSQL_INSTANCE_CREDS"
  },
  "metadata": {
    "name": "cloudsql-instance-credentials"
  }
}
EOF

kubectl create -f - <<EOF
{
  "apiVersion": "v1",
  "kind": "Secret",
  "type": "Opaque",
  "data": {
    "balmy-ground-195100-d9b0f3de3013.json": "$DARK_CLUSTER_STATIC_ASSETS_CREDS"
  },
  "metadata": {
    "name": "dark-static-assets"
  }
}
EOF

print_step "deploying code and containers"

./scripts/gke-deploy \
  "--region=${DARK_CLUSTER_REGION}" \
  "--project=${DARK_CLUSTER_PROJECT}" \
  "--cluster=${DARK_CLUSTER}"

print_step "waiting for a new ip..."

NEW_BWD_IP=null
while [ "$NEW_BWD_IP" == "null" ]; do
  NEW_BWD_IP="$(kubectl get Ingress bwd-tls-ingress -o json | jq -r '.status.loadBalancer.ingress[0].ip')"
done

NEW_DL_IP=null
while [ "$NEW_DL_IP" == "null" ]; do
  NEW_DL_IP="$(kubectl get Ingress darklang-tls-ingress -o json | jq -r '.status.loadBalancer.ingress[0].ip')"
done

print_step "your new cluster is deployed!"
cat <<EOF
Your new IPs are $(tput rev)$NEW_BWD_IP$(tput sgr0) (for builtwithdark) and
$(tput rev)$NEW_DL_IP$(tput sgr0) (for darklang). Wait a little for the
containers to come up...

   watch -d -n 0.2 kubectl get pods

and check it out one of the following ways:

  + edit your /etc/hosts to point builtwithdark.com and *.builtwithdark.com
    to that IP

    $NEW_BWD_IP		builtwithdark.com
    $NEW_BWD_IP	  some-subdomain.builtwithdark.com
    $NEW_DL_IP		darklang.com
    $NEW_DL_IP		static.darklang.com

  + use --resolve in 'curl', e.g.

    curl --resolve "builtwithdark.com:443:$NEW_BWD_IP" https://builtwithdark.com
    curl --resolve "darklang.com:443:$NEW_DL_IP" https://darklang.com

If you're tempted to move the static IPs from the old cluster to this
one, try it out a few times outside of production first. Moving the
static IPs the obvious way is flaky and seems nondeterministic. You
may have better luck swapping DNS if you need it and can live with the
long propagation times.
EOF
