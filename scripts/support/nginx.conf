## gzip makes responses much smaller
gzip on;

## nginx assumes proxies can't handle gzip. That's wrong in our case;
## the gke load-balancer will handle it fine, and in fact needs a gzipped
## response to gzip.
## http://nginx.org/en/docs/http/ngx_http_gzip_module.html#gzip_proxied
gzip_proxied any;

## gzip these mime types. some other types of files are already gzipped
## in a content-aware way (e.g. png, jpeg) so it probably doesn't make
## sense to re-gzip them. (text/html isn't in this configuration file
## because it's always there, and including it makes nginx warn. )
gzip_types text/plain text/css application/javascript application/json;

# don't gzip small files.
gzip_min_length 1024;

## when you're writing a new route for proxying, consider the following...

## We need to include the following two things everywhere we want
## to proxy to the Dark backend.

## If we don't proxy_set_header Host, it'll be 'localhost',
## which the backend won't know how to dispatch on.

  # proxy_set_header Host $host;

## proxy_pass will cause all other headers will get passed by default,
## including, for example x-forwarded-for and x-forwarded-proto, so that
## the OCaml application can know what the user or end-user visited.

  # proxy_pass http://localhost:80;

## N.B., don't include a trailing slash when you proxy_pass.
## That changes the semantics of the proxying to only append
## the unmatched part of the location to the proxy URL, rather
## then append the whole path to the proxy domain.

proxy_cache_path /tmp/cache/ levels=1:2 keys_zone=static_cache:100k max_size=100m;

server {
  listen 8000;
  server_name www.darklang.com;
  return 301 https://darklang.com$request_uri;
}

server {
  listen 8000;
  server_name darklang.com;
  # At least in theory, we could put client_max_body_size under a location {},
  # so we could add a location /api/*/static_assets {}, to leave the default of
  # 1m in place elsewhere. Stack overflow disagrees; unclear whether this may be
  # due to different nginx versions. So for now, doing it more broadly to be
  # safe.
  client_max_body_size 100m;

  # These prefixes are handled by the OCaml backend.
  location /a/ {
    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }
  location /api/ {
    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }
  # The rest of the routes should proxy to the marketing site.
  location / {
    # redirect http to https.
    if ($http_x_forwarded_proto = "http") {
      rewrite ^(.*)$ https://$server_name$1 permanent;
    }
    proxy_pass https://darklang-com.netlify.com;
  }
}

server {
  listen 8000;
  server_name static.darklang.com;

  location / {
    # cache this content on the fs of the nginx container, rather than letting
    # the OCaml Dark backend do it (assuming nginx is faster at it than cohttp).
    proxy_cache static_cache;
    # browsers should cache this for a week, but ask the server every time whether
    # it has a new one with a new ETag via If-None-Match.
    add_header Cache-control "public, must-revalidate";
    expires 7d;
    etag on;

    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }
}

server {
  listen 8000 default_server;
  listen [::]:8000 default_server;

  # The backend only serves /pkill when it's not darklang.com,
  # builtwithdark.com, *.builtwithdark.com, or similar. So because
  # this is the only `server' section for which that will be true,
  # we only need to block /pkill here.
  location =/pkill {
    return 403;
  }
  # static.darklang.com, builtwithdark.com, *.builtwithdark.com,
  # and the IP address directly are handled by the OCaml backend.
  location / {
    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }
}
