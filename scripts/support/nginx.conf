## gzip makes responses much smaller
gzip on;

## nginx assumes proxies can't handle gzip. That's wrong in our case;
## the gke load-balancer will handle it fine, and in fact needs a gzipped
## response to gzip.
## http://nginx.org/en/docs/http/ngx_http_gzip_module.html#gzip_proxied
roxied any;

## gzip these mime types. some other types of files are already gzipped
## in a content-aware way (e.g. png, jpeg) so it probably doesn't make
## sense to re-gzip them. (text/html isn't in this configuration file
## because it's always there, and including it makes nginx warn. )
gzip_types text/plain text/css application/javascript application/json;

# don't gzip small files.
gzip_min_length 1024;

## when you're writing a new route for proxying, consider the following...

## We need to include the following two things everywhere we want
## to proxy to the Dark backend.

## If we don't proxy_set_header Host, it'll be 'localhost',
## which the backend won't know how to dispatch on.

  # proxy_set_header Host $host;

## proxy_pass will cause all other headers will get passed by default,
## including, for example x-forwarded-for and x-forwarded-proto, so that
## the OCaml application can know what the user or end-user visited.

  # proxy_pass http://localhost:80;

## N.B., don't include a trailing slash when you proxy_pass.
## That changes the semantics of the proxying to only append
## the unmatched part of the location to the proxy URL, rather
## then append the whole path to the proxy domain.

proxy_cache_path /tmp/cache/ levels=1:2 keys_zone=static_cache:100k max_size=100m;

# log_format for honeycomb/honeytail: https://docs.honeycomb.io/getting-data-in/integrations/webservers/nginx/#optional-configuration
# added: x-darklang-execution-id
# added: cookie (so we know which user did a thing)
log_format honeycomb '$remote_addr - $remote_user [$time_local] $host '
    '"$request" $status $bytes_sent $body_bytes_sent $request_time '
    '"$http_referer" "$http_user_agent" $request_length "$http_authorization" '
    '"$http_x_forwarded_proto" "$http_x_forwarded_for" $server_name '
    '"$upstream_http_x_darklang_execution_id" "$http_cookie" "$upstream_http_x_dark_username"';
access_log /var/log/nginx/access.log honeycomb;

# 'trust' all ips, rather than the footgun of "oops, changed our incoming ip,
# forgot to update nginx". We're using this remote_addr value for stats, not
# auth, so untrusted is ok.
set_real_ip_from 0.0.0.0/0;
set_real_ip_from ::/0;

real_ip_header X-Forwarded-For;
real_ip_recursive on;

# Tune nginx keepalives to work with the GCP HTTP(S) Load Balancer, per
# https://blog.percy.io/tuning-nginx-behind-google-cloud-platform-http-s-load-balancer-305982ddb340
keepalive_timeout 650;
keepalive_requests 10000;

server {
  listen 8000;
  server_name www.darklang.com;

  # tell clients to stop going to http://www.darklang.com
  add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;

  return 301 https://darklang.com$request_uri;
}

server {
  listen 8000;
  server_name darklang.com;
  # At least in theory, we could put client_max_body_size under a location {},
  # so we could add a location /api/*/static_assets {}, to leave the default of
  # 1m in place elsewhere. Stack overflow disagrees; unclear whether this may be
  # due to different nginx versions. So for now, doing it more broadly to be
  # safe.
  client_max_body_size 100m;

  # tell clients to stop going to http://darklang.com
  add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;

  # These prefixes are handled by the OCaml backend.
  location /a/ {
    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }
  location /api/ {
    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }
  location /login {
    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }
  location /logout {
    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }

  # Note - this needs to be in both the prod server at the top & the catch-all
  # at the bottom for local
  # From https://www.mediasuite.co.nz/blog/proxying-s3-downloads-nginx/
  location ~ ^/user-login {
    # Only allow internal redirects
    internal;
    # How to resove remote URLs, you may want to update this depending
    # on your setup, in our case it’s inside a Docker container with
    # dnsmasq running.
    # resolver 127.0.0.1 ipv6=off;
    # Reconstruct the remote URL
    set $download_url https://ops-corpsite.builtwithdark.com/login;
    # Headers for the remote server, unset Authorization and Cookie for security reasons.
    proxy_set_header Host ops-corpsite.builtwithdark.com;
    proxy_set_header Authorization '';
    proxy_set_header Cookie '';
    # Headers for the response, by using $upstream_http_... here we can inject
    # other headers from Django, proxy_hide_header ensures the header from the
    # remote server isn't passed through.
    proxy_hide_header Content-Disposition;
    add_header Content-Disposition $upstream_http_content_disposition;
    # Stops the local disk from being written to (just forwards data through)
    proxy_max_temp_file_size 0;
    # Proxy the remote file through to the client
    proxy_pass $download_url$is_args$args;
  }

  # The rest of the routes should proxy to the marketing site.
  location / {
    # redirect http to https.
    if ($http_x_forwarded_proto = "http") {
      rewrite ^(.*)$ https://$server_name$1 permanent;
    }

    proxy_set_header X-Forwarded-Host $host;
    proxy_pass https://ops-corpsite.builtwithdark.com;
  }
}

server {
  listen 8000;
  server_name presence.darklang.com;

  # tell clients to stop going to http://presence.darklang.com
  add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;

  location / {
    # redirect http to https.
    if ($http_x_forwarded_proto = "http") {
      rewrite ^(.*)$ https://$server_name$1 permanent;
    }

    proxy_set_header X-Forwarded-Host $host;
    proxy_pass https://sydney-presence.builtwithdark.com;
  }
}

server {
  listen 8000;
  server_name static.darklang.com;

  # tell clients to stop going to http://static.darklang.com
  add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;

  location / {
    # cache this content on the fs of the nginx container, rather than letting
    # the OCaml Dark backend do it (assuming nginx is faster at it than cohttp).
    proxy_cache static_cache;
    # browsers should cache this for a week, but ask the server every time whether
    # it has a new one with a new ETag via If-None-Match.
    add_header Cache-control "public, must-revalidate";
    expires 7d;
    etag on;

    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }
}

server {
  listen 8000;
  server_name hellobirb.com;
  return 301 $http_x_forwarded_proto://www.hellobirb.com$request_uri;
}

server {
  listen 8000;
  server_name talkpay.club;
  return 301 $http_x_forwarded_proto://www.talkpay.club$request_uri;
}

server {
  listen 8000;
  server_name kiksht.com;
  return 301 $http_x_forwarded_proto://www.kiksht.com$request_uri;
}

server {
  listen 8000 default_server;
  listen [::]:8000 default_server;

  # No Strict-Transport-Security here. It's possible we'll set it on the backend
  # for canvases in the future, but there are some open questions about custom
  # domains and Dark users overriding headers.

  # The backend only serves /pkill when it's not darklang.com,
  # builtwithdark.com, *.builtwithdark.com, or similar. So because
  # this is the only `server' section for which that will be true,
  # we only need to block /pkill here.
  location =/pkill {
    return 403;
  }
  # static.darklang.com, builtwithdark.com, *.builtwithdark.com,
  # and the IP address directly are handled by the OCaml backend.
  location / {
    proxy_set_header Host $host;
    proxy_pass http://localhost:80;
  }

  # Note - this needs to be in both the prod server at the top & the catch-all
  # at the bottom for local
  # From https://www.mediasuite.co.nz/blog/proxying-s3-downloads-nginx/
  location ~ ^/user-login {
    # Only allow internal redirects
    internal;
    # How to resove remote URLs, you may want to update this depending
    # on your setup, in our case it’s inside a Docker container with
    # dnsmasq running.
    # resolver 127.0.0.1 ipv6=off;
    # Reconstruct the remote URL
    set $download_url https://ops-corpsite.builtwithdark.com/login;
    # Headers for the remote server, unset Authorization and Cookie for security reasons.
    proxy_set_header Host ops-corpsite.builtwithdark.com;
    proxy_set_header Authorization '';
    proxy_set_header Cookie '';
    # Headers for the response, by using $upstream_http_... here we can inject
    # other headers from Django, proxy_hide_header ensures the header from the
    # remote server isn't passed through.
    proxy_hide_header Content-Disposition;
    add_header Content-Disposition $upstream_http_content_disposition;
    # Stops the local disk from being written to (just forwards data through)
    proxy_max_temp_file_size 0;
    # Proxy the remote file through to the client
    proxy_pass $download_url$is_args$args;
  }
}
