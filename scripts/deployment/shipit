#!/usr/bin/env python3

# Script to manage deployment/release of kubernetes services

# See description in services/README.md

import os
import sys

if os.getenv("IN_DEV_CONTAINER") != "true":
  print("Must be run in dev container")
  sys.exit(1)

import argparse
import glob
import jsonschema
import os.path
import re
import subprocess
import yaml
import hashlib
import json
import rich

##################################
# Utility functions
##################################


def bad(str):
  print(str)
  sys.exit(1)


should_debug = False
should_dry_run = False
dry_run_target = None

# When running diffs, keep going through the errors but make sure to report something
error = None


def handle_error(msg):
  global error
  print(msg)
  if error is None:
    error = msg


def debug(str, str2=None, str3=None):
  if should_debug:
    if str2 != None:
      str = f"{str} {str2}"
    if str3 != None:
      str = f"{str} {str3}"
    rich.print(f"[bold red]DEBUG: {str}[/bold red]")


def readfile(filename):
  with open(filename, "r") as f:
    return f.read()


def writefile(filename, contents):
  with open(filename, "w") as f:
    f.write(contents)


def clean_filename(filename):
  abs = os.path.abspath(filename)
  rel = os.path.relpath(abs, os.getcwd())
  return rel


# Run an important command, keeping stdout/stderr going to the user
def run(name, args, shell=False, input=None, stop_on_error=True):
  try:
    if should_dry_run:
      color = "bold green"
    else:
      color = "bold magenta"
    rich.print(f"[{color}]Running `{name}` command[/{color}]")
    print(args)
    subprocess.run(args, shell=shell, input=input, check=True)
    print()
  except subprocess.CalledProcessError as e:
    msg = f"Error running {name} command:\n  {e}\n"
    if stop_on_error:
      bad(msg)
    else:
      handle_error(msg)


# Runs a command that's part of running the script, captures stdout
def run_output(args, shell=False, input=None, stop_on_error=True, env=None):
  try:
    if env != None:
      env = {**os.environ, **env}  # merge two dicts in python 3.8
    if should_dry_run:
      color = "bold green"
    else:
      color = "bold magenta"
    rich.print(f"[{color}]Running `{args}` command[/{color}]")

    return subprocess.check_output(args, shell=shell, env=env,
                                   input=input).decode("utf-8").strip()
  except subprocess.CalledProcessError as e:
    msg = f"Error running command:\n  {e}\n"
    if stop_on_error:
      bad(msg)
    else:
      handle_error(msg)


##################################
# definitions
##################################
REGION = "us-west1"
PROJECT = "balmy-ground-195100"
CLUSTER = readfile("current-cluster")
CLOUDSQL_INSTANCE_NAME = "balmy-ground-195100:us-west1:dark-west"
DEPLOY_LOCK_BUCKET = "gs://darklang-deploy-lock"

##################################
# Assertions
##################################


def assert_file_exists(dir, f):
  if not os.path.exists(os.path.join(dir, f)):
    bad(f"File {dir}/{f} does not exist")


def assert_dir_exists(service, d):
  if not os.path.exists(d):
    bad(f"Directory {d} does not exist")


def assert_string_in_file(filename, file_str, substr):
  if substr not in file_str:
    bad(f"String missing from {filename}: {substr}")


##################################
# Load services / config
##################################
def get_service_dirs(args):
  dirs = args.services
  if dirs == []:
    dirs = [path for path in glob.glob(r'services/**') if "README.md" not in path]
  elif len(dirs) == 1 and dirs[0].endswith("shipit.yaml"):
    dirs = [os.path.dirname(dirs[0])]
  sorted_dirs = sorted(dirs)
  return sorted_dirs


def get_service_config(dir):
  try:
    file = open(dir + "/shipit.yaml")
  except:
    bad(f"Missing config file in {dir}/shipit.yaml")
  try:
    return yaml.load(file, Loader=yaml.Loader)
  except Exception as e:
    bad(f"Bad yaml in {dir}/shipit.yaml\n  {e}")


##################################
# Configmaps are present in both manually-deployed and automatically released config
##################################


def get_hashed_configmap_name(dir, name, desc):
  cm_filename = desc.get("text-file", desc.get("env-file"))
  cm_contents = readfile(os.path.join(dir, cm_filename))
  hash = hashlib.sha256(cm_contents.encode("utf-8")).hexdigest()[0:12]
  return f"{name}-{hash}"


def collect_versioned_configmaps(dir, parent):
  cms = {}
  for name, cm in parent.get("versioned-configmaps", {}).items():
    hashed_name = get_hashed_configmap_name(dir, name, cm)
    filespec = read_config_map_source(dir, cm)
    cms[hashed_name] = filespec
  return cms


##################################
# Config commands
##################################


def get_all_config_file_arguments(args):
  files = []
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    for f in config['k8s']["manually-deployed"]["configs"]:
      files.append(os.path.join(dir, f))

  file_args = []
  for f in files:
    file_args.append("-f")
    file_args.append(f)
  return file_args


def read_config_map_source(dir, cm):
  text_file = cm.get("text-file")
  if text_file:
    filename = clean_filename(os.path.join(dir, text_file))
    return f"--from-file={filename}"
  else:
    env_file = cm["env-file"]
    filename = clean_filename(os.path.join(dir, env_file))
    return f"--from-env-file={filename}"


def manual_diff(args):
  do_validation(args)

  # Config files
  file_args = get_all_config_file_arguments(args)
  if file_args == []:
    debug("No configs to diff, skipping")
  else:
    run("kubectl diff", ["kubectl", "diff"] + file_args, stop_on_error=False)

  # Configmaps
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    cms = config['k8s'].get("manually-deployed").get("configmaps", {})
    for name, cm in cms.items():
      filespec = read_config_map_source(dir, cm)
      run("kubectl diff configmap",
          f"kubectl create configmap {name} {filespec} --dry-run=client -o yaml | kubectl diff --filename=-",
          shell=True,
          stop_on_error=False)

  # Custom diff
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    manual = config['k8s'].get("manually-deployed")
    for c in manual.get("custom-diff", []):
      run("custom diff", c, shell=True, stop_on_error=False)


def manual_apply(args):
  args.services = [args.service]
  do_validation(args)

  # Config files
  file_args = get_all_config_file_arguments(args)
  if file_args == []:
    debug("No configs to apply, skipping")
  else:
    if should_dry_run:
      run("kubectl apply",
          ["kubectl", "apply", f"--dry-run={dry_run_target}"] + file_args)
    else:
      run("kubectl apply", ["kubectl", "apply"] + file_args)

  # Configmaps
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    cms = config['k8s'].get("manually-deployed", {}).get("configmaps", {})
    for name, cm in cms.items():
      filespec = read_config_map_source(dir, cm)
      if should_dry_run:
        run("kubectl apply configmap (dry-run)",
            f"kubectl create configmap {name} {filespec} --dry-run=client -o yaml | kubectl apply --filename=- --dry-run={dry_run_target}",
            shell=True)
      else:
        run("kubectl apply configmap",
            f"kubectl create configmap {name} {filespec} --dry-run=client -o yaml | kubectl apply --filename=-",
            shell=True)

  # Custom apply
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    manual = config['k8s'].get("manually-deployed", {})
    for c in manual.get("custom-apply", []):
      if should_dry_run:
        print(f"skipping custom apply step: {c}")
      else:
        run("custom apply", c, shell=True)

  # Custom post-apply (used for restarting services)
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    manual = config['k8s'].get("manually-deployed", {})
    for c in manual.get("custom-post-apply", []):
      if should_dry_run:
        print(f"skipping post apply step: {c}")
      else:
        run("custom post apply", c, shell=True)


##################################
# Manifests
##################################
def manifest_validate(args, shas):
  containers = get_service_containers(args)
  keys = set(shas.keys())
  for c in containers:
    if c not in keys:
      bad(f"Expected a sha for all containers, none found for {c}")
  for (c, sha) in shas.items():
    if sha is None:
      bad(f"Expected a sha for all containers, none found for {c}")
    if sha == "":
      bad(f"Empty sha found for {c}")
    if re.match("[a-f0-9]{9}", sha) is None:
      bad(f"Sha does not match expected format: {c}")


def manifest_save(args, shas):
  manifest_validate(args, shas)
  with open(args.save_manifest, "w") as f:
    json.dump(shas, f, indent=2, sort_keys=True)
  print(f"Saved manifest in {args.save_manifest}")


def manifest_load(args):
  with open(args.manifest, "r") as f:
    shas = json.load(f)
  manifest_validate(args, shas)
  return shas


##################################
# Container commands
##################################


def get_service_containers(args):
  needed_containers = set()
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    containers = config['k8s'].get("release", {"containers": []})["containers"]
    for c in containers:
      needed_containers.add(c)
  return needed_containers


def containers_list(args):
  do_validation(args)
  status = run_output(["docker", "image", "ls"]).split("\n")
  service_containers = get_service_containers(args)
  for line in status:
    for c in service_containers:
      if c in line:
        print(line)
        break


def containers_pull(args):
  print("Pulling, if error you might need `gcloud auth configure-docker`")
  shas = {}
  do_validation(args)
  for c in get_service_containers(args):
    url = f"gcr.io/{PROJECT}/{c}"
    image = f"gcr.io/{PROJECT}/{c}:latest"
    run("docker pull", ["docker", "pull", image])
    # Now get the ID we just pulled
    id = run_output(["docker", "images", url, "-q"]).split("\n")[0]
    shas[c] = id
  manifest_save(args, shas)


def containers_push(args):
  print("Pushing, if error you might need `gcloud auth configure-docker`")
  do_validation(args)

  def image_info(c):
    image_id = run_output([f"docker images -q {c} | head -n 1"], shell=True)
    url = f"gcr.io/{PROJECT}/{c}"
    return type('', (object, ), {
        'image': f"{url}:{image_id}",
        'image_latest': f"{url}:latest"
    })()

  for c in get_service_containers(args):
    info = image_info(c)
    run("docker tag id", ["docker", "tag", f"{c}:latest", info.image])
    run("docker tag latest", ["docker", "tag", f"{c}:latest", info.image_latest])

  for c in get_service_containers(args):
    info = image_info(c)
    run("docker push", ["docker", "push", info.image])
    run("docker push", ["docker", "push", info.image_latest])


def containers_build(args):
  do_validation(args)

  def build(name, dockerfilename, commitSha):
    print(f"building {name} docker image")
    dockerfile = readfile(dockerfilename)
    if commitSha:
      run("docker build", [
          "docker", "build", "--tag", f"{name}:latest", "--build-arg",
          f"GIT_COMMIT={commitSha}", "-"
      ],
          input=dockerfile.encode("utf-8"))
    else:
      run("docker build", ["docker", "build", "--tag", f"{name}:latest", "-"],
          input=dockerfile.encode("utf-8"))

  commitSha = run_output(["git", "rev-parse", "--short", "HEAD"])
  build("dark-base-service", "containers/base-service-Dockerfile", commitSha)
  build("dark-ocaml-service", "containers/ocaml-service-Dockerfile", None)
  build("dark-fsharp-service", "containers/fsharp-service-Dockerfile", None)

  # Each container name represents a container in containers/. If there's a prep.sh
  # file in the dir, run it first and then build the container in the directory it
  # echos. If there is no dockerfile, then do nothing (sometimes we use vendor
  # containers and so we just need to store config files).
  shas = {}
  for c in get_service_containers(args):
    dir = os.path.join("containers", c)
    if os.path.isdir(dir) and os.path.exists(os.path.join(dir, "Dockerfile")):
      print(f"\nBuild container {c}")
      prep = os.path.join(dir, "prep.sh")
      if os.path.exists(prep):
        dir = run_output(prep)
      sha = run_output(["docker", "build", "--quiet", "--tag", f"{c}:latest", dir])
      sha = sha[7:19]
      print(sha)
      shas[c] = sha
    else:
      print(f"\nNo dockerfile, skipping {c}")
  manifest_save(args, shas)


##################################
# Releases
##################################
def get_expected_args(args):
  expected_args = {}
  for arg in args.arg or []:
    items = arg.strip().split("=")
    k = items[0].strip()
    v = "=".join(items[1:]).strip()
    if (v.startswith("\"") and v.endswith("\"")) or \
       (v.startswith("'") and v.endswith("'")):
      v = v[1:-1]
    expected_args[k] = v
  return expected_args


def collect_release_templated_configs(args):
  files = []
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    release = config['k8s'].get("release")
    if release:
      filename = os.path.join(dir, release["config-template"])
      target_filename = filename.replace(".template", "")
      files.append(target_filename)
  return files


def release_prepare(args):
  do_validation(args)
  builtins = {"CLOUDSQL_INSTANCE_NAME": CLOUDSQL_INSTANCE_NAME}
  expected_args = get_expected_args(args)
  ids = manifest_load(args)
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    release = config['k8s'].get("release")
    if release:
      filename = os.path.join(dir, release["config-template"])

      # Fill in the blanks
      content = readfile(filename)
      for c in release["containers"]:
        v = ids[c]
        if v == None:
          bad(f"No value for `IMAGEID:{c}")
        if v == "":
          bad(f"Empty string for `IMAGEID:{c}")
        content = content.replace(f"{{IMAGEID:{c}}}", v)
      for name, desc in release.get("versioned-configmaps", {}).items():
        hashed_name = get_hashed_configmap_name(dir, name, desc)
        content = content.replace(f"{{VERSIONED-CONFIGMAP:{name}}}", hashed_name)
      for a in release.get("expected-args", []):
        value = expected_args.get(a)
        if value == None:
          bad(f"No value provided for `ARG:{a}. Pass it at the command line using `--arg {a}='SOME VALUE'`"
              )
        if value == "":
          bad(f"Empty string provided for `ARG:{a}. Pass it at the command line using `--arg {a}='SOME VALUE'`"
              )
        content = content.replace(f"{{ARG:{a}}}", expected_args[a])
      for v in release.get("builtins", []):
        b = builtins[v]
        if b == None:
          bad(f"No value for `BUILTIN:{v}. Probably an internal error")
        if b == "":
          bad(f"Empty string for `BUILTIN:{v}. Probably an internal error")
        content = content.replace(f"{{BUILTIN:{v}}}", b)

      # Write the non-template version
      target_filename = filename.replace(".template", "")
      rich.print(
          f"[italic yellow]Writing release file: {target_filename}[/italic yellow]")
      writefile(target_filename, content)


# Read the current container shas from production
def release_current_manifest(args):
  do_validation(args)
  shas = {}
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    containers = set(config['k8s'].get("release", {}).get("containers", []))
    # Only check yamls with a containers section
    if len(containers) > 0:
      service_name = os.path.basename(dir)
      k8s_config = run_output(f"kubectl get deployments/{service_name} -o json",
                              shell=True)
      k8s_config = json.loads(k8s_config)
      for c in k8s_config['spec']['template']['spec']['containers']:
        [name, version] = c['image'].split(":")
        name = name.split("/")[-1]
        # only use containers listed in config, as those are the only ones shipit manages
        if name in containers:
          if shas.get(name) == None:
            shas[name] = version
          else:
            # check we use the same version across all services
            if shas[name] != version:
              bad(f"{name} has multiple versions: {shas[name]} and {version}")
      for c in containers:
        if shas.get(c) == None:
          bad(f"{c} not found in manifest")
  manifest_save(args, shas)


def release_diff(args):
  do_validation(args)
  release_prepare(args)

  # Configmaps
  all_configmaps = {}
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    release = config['k8s'].get("release")
    if release:
      maps = collect_versioned_configmaps(dir, release)
      all_configmaps.update(maps)
  for hashed_name, filespec in all_configmaps.items():
    run("kubectl diff configmap",
        f"kubectl create configmap {hashed_name} {filespec} --dry-run=client -o yaml | kubectl diff --filename=-",
        shell=True,
        stop_on_error=False)

  # diff it against production
  files = collect_release_templated_configs(args)
  if files == []:
    debug("No release configs to diff, skipping")
  else:
    file_args = ["kubectl", "diff"]
    for f in files:
      file_args.append("-f")
      file_args.append(f)
    run("kubectl diff", file_args, stop_on_error=False)


def release_push(args):
  do_validation(args)
  release_prepare(args)

  # Do the config maps first, as they're used by the deploys
  all_configmaps = {}
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    release = config['k8s'].get("release")
    if release:
      maps = collect_versioned_configmaps(dir, release)
      all_configmaps.update(maps)
  for hashed_name, filespec in all_configmaps.items():
    if should_dry_run:
      run("kubectl apply configmap",
          f"kubectl create configmap {hashed_name} {filespec} --dry-run=client -o yaml | kubectl apply --filename=- --dry-run={dry_run_target}",
          shell=True)
    else:
      run("kubectl apply configmap",
          f"kubectl create configmap {hashed_name} {filespec} --dry-run=client -o yaml | kubectl apply --filename=-",
          shell=True)

  files = collect_release_templated_configs(args)

  # diff it against production
  if files == []:
    debug("No release configs to apply, skipping")
  else:
    file_args = []
    for f in files:
      file_args.append("-f")
      file_args.append(f)
    if should_dry_run:
      run("kubectl apply --dry-run",
          ["kubectl", "apply", f"--dry-run={dry_run_target}"] + file_args)
    else:
      run("kubectl apply", ["kubectl", "apply"] + file_args)


##################################
# Validate config files
##################################

config_schema = """
type: object
properties:
  k8s:
    type: object
    properties:
      manually-deployed:
        type: object
        properties:
          configs:
            type: array
            items:
              type: string
          configmaps:
            type: object
            additionalProperties:
              type: object
              propertyNames:
                pattern: "^[a-z][-a-z0-9]*$"
              properties:
                text-file:
                  type: string
                env-file:
                  type: string
              additionalProperties: false
          custom-diff:
            type: array
            items:
              type: string
          custom-apply:
            type: array
            items:
              type: string
          custom-post-apply:
            type: array
            items:
              type: string
        additionalProperties: false
        required: [configs]
      release:
        type: object
        properties:
          config-template:
            type: string
          containers:
            type: array
            items:
              type: string
          versioned-configmaps:
            additionalProperties:
              type: object
              propertyNames:
                pattern: "^[a-z][-a-z0-9]*$"
              properties:
                text-file:
                  type: string
                env-file:
                  type: string
              additionalProperties: false
          expected-args:
            type: array
            items:
              type: string
          builtins:
            type: array
            items:
              type: string
        required: [containers, config-template]
        additionalProperties: false
    required: [manually-deployed]
    additionalProperties: false
"""


def do_validation(args):
  def validate_configmaps(configmaps):
    if configmaps is None:
      return
    for name, desc in configmaps.items():
      from_file = desc.get("text-file") or desc.get("env-file")
      if from_file:
        assert_file_exists(dir, from_file)
      else:
        bad(f"Need either `text-file` or `env-file` for {name}")

  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    debug(f"Validating config for {dir}")
    try:
      jsonschema.validate(config, yaml.load(config_schema, Loader=yaml.Loader))
    except jsonschema.exceptions.ValidationError as e:
      bad(f"Error in {dir}/shipit.yaml:\n  {e}")

    k8s = config['k8s']

    manually_deployed = k8s["manually-deployed"]
    validate_configmaps(manually_deployed.get("configmaps"))
    configs = manually_deployed["configs"]
    for f in configs:
      assert_file_exists(dir, f)

    release = config['k8s'].get("release", None)
    if release:
      validate_configmaps(release.get("versioned-configmaps"))
      assert_file_exists(dir, release['config-template'])
      template_filename = os.path.join(dir, release['config-template'])
      template_contents = open(template_filename).read()

      for c in release["containers"]:
        assert_dir_exists(dir, f"containers/{c}")
        # Check the containers are used in the template
        assert_string_in_file(template_filename, template_contents,
                              f"{{IMAGEID:{c}}}")

      # Check the vars are used in the template
      for var in release.get("builtins", []):
        assert_string_in_file(template_filename, template_contents,
                              f"{{BUILTIN:{var}}}")
      for var in release.get("expected-args", []):
        assert_string_in_file(template_filename, template_contents, f"{{ARG:{var}}}")
      for name in release.get("versioned-configmaps", {}).keys():
        assert_string_in_file(template_filename, template_contents,
                              f"{{VERSIONED-CONFIGMAP:{name}}}")

      # Check all template vars are defined
      for match in re.findall(r"\{([-A-Z0-9a-z:_]+)}", template_contents,
                              re.MULTILINE):
        builtin_match = re.match(r"^BUILTIN:([A-Z0-9_]+)$", match)
        expectedarg_match = re.match(r"^ARG:([A-Z0-9_]+)$", match)
        imageid_match = re.match(r"^IMAGEID:([-a-z0-9]+)$", match)
        versioned_configmap_match = re.match(r"^VERSIONED-CONFIGMAP:([-a-z0-9]+)$",
                                             match)
        if builtin_match:
          builtin = builtin_match.group(1)
          if builtin not in release["builtins"]:
            bad(f"builtin \"{builtin}\" not in `k8s.release.builtins` in {template_filename}"
                )

        elif expectedarg_match:
          expectedarg = expectedarg_match.group(1)
          if expectedarg not in release["expected-args"]:
            bad(f"expected arg \"{expectedarg}\" not in `k8s.release.expected-args` in {template_filename}"
                )

        elif imageid_match:
          id = imageid_match.group(1)
          if id not in release["containers"]:
            bad(f"imageid \"{id}\" not in `k8s.release.containers` in {template_filename}"
                )

        elif versioned_configmap_match:
          name = versioned_configmap_match.group(1)
          if name not in release.get("versioned-configmaps", {}):
            bad(f"configmap \"{name}\" not in `k8s.release.versioned-configmaps` in {template_filename}"
                )
        else:
          bad(f"Unexpected placeholder \"{{{match}}}\" in\n{template_filename}")


def validate(args):
  do_validation(args)
  print("All shipit.yaml files successfully validated")


##################################
# Argument parser
##################################


def create_arg_parser():
  # The base parser has the commands shared by ALL subcommands
  base_parser = argparse.ArgumentParser(add_help=False)
  base_parser.add_argument('--debug',
                           action='store_true',
                           help="Print debug info about what's running")
  base_parser.add_argument(
      '--dry-run',
      choices=['server', 'client'],
      action='store',
      help="paths to the service definitions. Leave empty to run on all services")
  base_parser.set_defaults(debug=False)
  base_parser.set_defaults(dry_run=False)

  # We want to be explicit about listing services for side-effecting commands
  services_parser = argparse.ArgumentParser(add_help=False)
  services_parser.add_argument(
      'services',
      action="store",
      nargs="*",
      help=
      "paths to the service definitions (directories within services/). Leave empty to run on all services"
  )

  output_manifest_parser = argparse.ArgumentParser(add_help=False)
  output_manifest_parser.add_argument('--save-manifest',
                                      action="store",
                                      required=True,
                                      help="path to store the release manifest")

  release_args_parser = argparse.ArgumentParser(add_help=False)
  release_args_parser.add_argument(
      '--manifest',
      action="store",
      required=True,
      help=
      "path to the release manifest, generated using `containers pull` or `containers build`"
  )
  release_args_parser.add_argument(
      '--arg',
      metavar="KEY=VALUE",
      action='append',
      help=
      "key/value pair that defines an `expected-arg` in the shipit.yamls. Provide once per key/value pair"
  )

  main_parser = argparse.ArgumentParser(
      description='Manage deployment of kubernetes services')
  main_subparsers = main_parser.add_subparsers()

  # Validate
  validate_parser = main_subparsers.add_parser(
      'validate',
      description="Validates shipit.yaml files",
      parents=[base_parser, services_parser])
  validate_parser.set_defaults(func=validate)

  # Manually applied things
  manual_parser = main_subparsers.add_parser('manual')
  manual_subparser = manual_parser.add_subparsers()

  manual_diff_parser = manual_subparser.add_parser(
      'diff',
      description=
      "Checks that the config files listed in the k8s.manually-deployed key of shipit.yaml are already properly deployed, using `kubectl diff`",
      parents=[base_parser, services_parser])
  manual_diff_parser.set_defaults(func=manual_diff)

  manual_apply_parser = manual_subparser.add_parser(
      'apply',
      description=
      "Checks that the config files listed in the k8s.manually-deployed key of shipit.yaml are already properly deployed, using `kubectl diff`",
      parents=[base_parser])
  manual_apply_parser.add_argument(
      'service',
      action="store",
      help=
      "path to the service definition. Required and only one service is supported")
  manual_apply_parser.set_defaults(func=manual_apply)

  # Containers
  containers_parser = main_subparsers.add_parser('containers')
  containers_subparser = containers_parser.add_subparsers()

  containers_build_parser = containers_subparser.add_parser(
      'build',
      description="Builds the container images needed by services; echoes a manifest",
      parents=[base_parser, services_parser, output_manifest_parser])
  containers_build_parser.set_defaults(func=containers_build)

  containers_pull_parser = containers_subparser.add_parser(
      'pull',
      description="Pull the remote docker images used by services, echoes a manifest",
      parents=[base_parser, services_parser, output_manifest_parser])
  containers_pull_parser.set_defaults(func=containers_pull)

  containers_push_parser = containers_subparser.add_parser(
      'push',
      description="Push local docker images used by services to gcr",
      parents=[base_parser, services_parser])
  containers_push_parser.set_defaults(func=containers_push)

  containers_list_parser = containers_subparser.add_parser(
      'list',
      description="List the docker images used by services",
      parents=[base_parser, services_parser])
  containers_list_parser.set_defaults(func=containers_list)

  # Releases
  release_parser = main_subparsers.add_parser('release')
  release_subparser = release_parser.add_subparsers()

  release_current_manifest_parser = release_subparser.add_parser(
      'current-manifest',
      description=
      "Reads the current manifest from production deployments; echoes a manifest",
      parents=[base_parser, services_parser, output_manifest_parser])
  release_current_manifest_parser.set_defaults(func=release_current_manifest)

  release_diff_parser = release_subparser.add_parser(
      'diff',
      description="Diffs the release against the production release",
      parents=[base_parser, services_parser, release_args_parser])
  release_diff_parser.set_defaults(func=release_diff)

  release_push_parser = release_subparser.add_parser(
      'push',
      description="Actually do the release",
      parents=[base_parser, services_parser, release_args_parser])
  release_push_parser.set_defaults(func=release_push)

  release_prepare_parser = release_subparser.add_parser(
      'prepare',
      description="Prepare the release, producing k8s yaml files",
      parents=[base_parser, services_parser, release_args_parser])
  release_prepare_parser.set_defaults(func=release_prepare)

  return main_parser


##################################
# Main
##################################


def main():
  global should_debug
  global should_dry_run
  global dry_run_target
  parser = create_arg_parser()
  args = parser.parse_args()
  should_debug = args.debug
  should_dry_run = args.dry_run in ['client', 'server']
  dry_run_target = args.dry_run
  args.func(args)
  if error:
    sys.exit(1)


main()
